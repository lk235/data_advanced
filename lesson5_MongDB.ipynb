{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first 3 results\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': ObjectId('59e6210a46106039a84389c6'),\n u'assembly': [u'Germany', u'Stuttgart'],\n u'bodyStyle': u'coup\\xe9',\n u'class': u'grand tourer',\n u'dimensions': {u'height': 1.27508,\n                 u'length': 4.52,\n                 u'weight': 1450.0,\n                 u'wheelbase': 2.5,\n                 u'width': 1.89},\n u'engine': [u'Porsche_928__1',\n             u'Porsche_928__2',\n             u'Porsche_928__3',\n             u'Porsche_928__4'],\n u'layout': u'front-engine rear-wheel-drive layout',\n u'manufacturer': u'Porsche',\n u'modelYears': [],\n u'name': u'Porsche 928',\n u'productionYears': [1977,\n                      1978,\n                      1979,\n                      1980,\n                      1981,\n                      1982,\n                      1983,\n                      1984,\n                      1985,\n                      1986,\n                      1987,\n                      1988,\n                      1989,\n                      1990,\n                      1991,\n                      1992,\n                      1993,\n                      1994,\n                      1995],\n u'transmission': [u'3-speed automatic',\n                   u'4-speed automatic',\n                   u'5-speed manual']}\n{u'_id': ObjectId('59e6210a46106039a84389c7'),\n u'bodyStyle': u'2+2 (car body style)',\n u'class': u'sports car',\n u'designer': u'Harm Lagaay',\n u'dimensions': {u'height': 1.27,\n                 u'length': 4.2,\n                 u'weight': 1080.0,\n                 u'width': 1.685},\n u'engine': u'Porsche_924__1',\n u'layout': u'front-engine rear-wheel-drive layout',\n u'manufacturer': u'Porsche',\n u'modelYears': [],\n u'name': u'Porsche 924',\n u'productionYears': [1976,\n                      1977,\n                      1978,\n                      1979,\n                      1980,\n                      1981,\n                      1982,\n                      1983,\n                      1984,\n                      1985,\n                      1986,\n                      1987,\n                      1988]}\n{u'_id': ObjectId('59e6210a46106039a84389c8'),\n u'assembly': [u'Germany', u'Neckarsulm'],\n u'bodyStyle': [u'convertible', u'coup\\xe9'],\n u'class': u'sports car',\n u'designer': u'Harm Lagaay',\n u'dimensions': {u'height': 1.27508,\n                 u'length': 4.318,\n                 u'wheelbase': 2.4003,\n                 u'width': 1.73482},\n u'engine': [u'Porsche_944__1', u'Porsche_944__2', u'Porsche_944__3'],\n u'layout': u'front-engine rear-wheel-drive layout',\n u'manufacturer': u'Porsche',\n u'modelYears': [],\n u'name': u'Porsche 944',\n u'productionYears': [1982,\n                      1983,\n                      1984,\n                      1985,\n                      1986,\n                      1987,\n                      1988,\n                      1989,\n                      1990,\n                      1991],\n u'transmission': [u'3-speed automatic', u'5-speed manual']}\n"
     ]
    }
   ],
   "source": [
    "# 练习: 查找保时捷\n",
    "# 题目说明\n",
    "# 你的任务是完成“porsche_query”函数，尤其是查找出制造商字段为“Porsche”的所有汽车的查询。\n",
    "# \n",
    "# 只需修改“porsche_query”函数，因为我们仅对该函数进行评分。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。\n",
    "# \n",
    "# 如果你想在本地机器上运行代码，你需要安装 MongoDB 并下载和插入数据集。要了解 MongoDB 设置和数据集方面的说明，\n",
    "# 请参阅课程资料，链接如下：https://www.udacity.com/wiki/ud032\n",
    "# 你可以查看 example_car.json 文件（第二个文件选项卡），找到作为查询依据的正确字段。\n",
    "# 有问题？ 你可以前往 优达学城论坛 与课程导师和其他学员一起\n",
    "\n",
    "import pymongo\n",
    "\n",
    "def porsche_query():\n",
    "    # Please fill in the query to find all autos manuafactured by Porsche.\n",
    "    query = {\"manufacturer\":\"Porsche\"}\n",
    "    return query\n",
    "\n",
    "\n",
    "# Do not edit code below this line in the online code editor.\n",
    "# Code here is for local use on your own computer.\n",
    "def get_db(db_name):\n",
    "    # For local use\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def find_porsche(db, query):\n",
    "    # For local use\n",
    "    return db.autos.find(query)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For local use\n",
    "    db = get_db('examples')\n",
    "    query = porsche_query()\n",
    "    results = find_porsche(db, query)\n",
    "\n",
    "    print \"Printing first 3 results\\n\"\n",
    "    import pprint\n",
    "    for car in results[:3]:\n",
    "        pprint.pprint(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_data_rate_limit`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'engine': u'Crawler-transporter__1', u'dimensions': {u'width': 34.7472, u'length': 39.9288, u'weight': 2721000.0}, u'transmission': u'16 traction motors powered by four  generators', u'modelYears': [], u'name': u'Crawler-transporter', u'productionYears': [], u'_id': ObjectId('59e6210a46106039a84389c3'), u'manufacturer': u'Marion Power Shovel Company'}\n46776\n"
     ]
    }
   ],
   "source": [
    "# 练习: 插入多个文档\n",
    "# 题目说明\n",
    "# 请向 insert_autos 函数中添加一行代码，将汽车数据插入“autos”集合中。\n",
    "# \n",
    "# process_file 函数返回的数据变量是一个字典列表，如上一个视频中展示的示例所示。\n",
    "# 对于本课程中使用的 MongoDB 版本，请查看此页面，了解 pymongo 中的批量插入。\n",
    "# \n",
    "# 在正式版本 3.0 中，该过程有轻微改变（详见此页面）。因此，当你在本地计算机上操作时，请注意这一点。\n",
    "# mongoimport -db dbname -c collectionname --file input-file.json\n",
    "\n",
    "from autos import process_file\n",
    "\n",
    "\n",
    "def insert_autos(infile, db):\n",
    "    data = process_file(infile)\n",
    "    \n",
    "    db.autos.insert_many(data)\n",
    "    # Add your code here. Insert the data in one command.\n",
    "    \n",
    "  \n",
    "if __name__ == \"__main__\":\n",
    "    # Code here is for local use on your own computer.\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient(\"mongodb://localhost:27017\")\n",
    "    db = client.examples\n",
    "\n",
    "    insert_autos('autos.csv', db)\n",
    "    print db.autos.find_one()\n",
    "    print db.autos.find().count()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found cities: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "no such item for Cursor instance",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-12560f431e73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Found cities:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcities\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\lk235\\Anaconda2\\lib\\site-packages\\pymongo\\cursor.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    584\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no such item for Cursor instance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m         raise TypeError(\"index %r cannot be applied to Cursor \"\n\u001b[0;32m    588\u001b[0m                         \"instances\" % index)\n",
      "\u001b[1;31mIndexError\u001b[0m: no such item for Cursor instance"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "# 练习: 范围查询\n",
    "# 题目说明\n",
    "# 你的任务是写一个查询，返回在二十一世纪建成的所有城市。\n",
    "# \n",
    "# 只需修改“range_query”函数，因为我们仅对该函数进行评分。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。\n",
    "# \n",
    "# 如果你想在本地机器上运行代码，你需要安装 MongoDB 并下载和插入数据集。\n",
    "# \n",
    "# 要了解 MongoDB 设置和数据集方面的说明，请参阅课程资料。\n",
    "# MongoDB 查询运算符参考。\n",
    "# \n",
    "# 请记住，2000 年不属于 21 世纪！\n",
    "\n",
    "from datetime import datetime\n",
    "    \n",
    "def range_query():\n",
    "    # Modify the below line with your query.\n",
    "    # You can use datetime(year, month, day) to specify date in the query\n",
    "    query = {\"foundingDate\": {\"$gte\":datetime(2001,1,1),\n",
    "                              }}\n",
    "    return query\n",
    "\n",
    "# Do not edit code below this line in the online code editor.\n",
    "# Code here is for local use on your own computer.\n",
    "def get_db():\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client.examples\n",
    "    return db\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For local use\n",
    "    db = get_db()\n",
    "    query = range_query()\n",
    "    cities = db.cities.find(query)\n",
    "\n",
    "    print \"Found cities:\", cities.count()\n",
    "    import pprint\n",
    "    pprint.pprint(cities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-4-df2f73ae3f1a>, line 37)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-df2f73ae3f1a>\"\u001b[1;36m, line \u001b[1;32m37\u001b[0m\n\u001b[1;33m    # pprint.pprint(a)\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# 练习: 使用 $In 运算符\n",
    "# 题目说明\n",
    "# 你的任务是写一个查询，返回由“Ford Motor Company”制造的并在德国、英国或日本组装的所有汽车。只需修改 in_query 函数，因为我们仅对该函数进行评分。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。\n",
    "# \n",
    "# 如果你想在本地机器上运行代码，你需要安装 MongoDB 并下载和插入数据集。\n",
    "# \n",
    "# 要了解 MongoDB 设置和数据集方面的说明，请参阅课程资料。\n",
    "\n",
    "def in_query():\n",
    "    # Modify the below line with your query; try to use the $in operator.\n",
    "    query = {'manufacturer':'Ford Motor Company','assembly':{'$in':['Germany','United Kingdom',\n",
    "                                                                    'Japan']}}\n",
    "    \n",
    "    return query\n",
    "\n",
    "\n",
    "# Do not edit code below this line in the online code editor.\n",
    "# Code here is for local use on your own computer.\n",
    "def get_db():\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client.examples\n",
    "    return db\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    db = get_db()\n",
    "    query = in_query()\n",
    "    autos = db.autos.find(query, {\"name\":1, \"manufacturer\":1, \"assembly\": 1, \"_id\":0})\n",
    "\n",
    "    print \"Found autos:\", autos.count()\n",
    "    import pprint\n",
    "    for a in autos:\n",
    "        # pprint.pprint(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first 3 results\n\n{u'_id': ObjectId('59e6210a46106039a84389c3'),\n u'dimensions': {u'length': 39.9288, u'weight': 2721000.0, u'width': 34.7472},\n u'engine': u'Crawler-transporter__1',\n u'manufacturer': u'Marion Power Shovel Company',\n u'modelYears': [],\n u'name': u'Crawler-transporter',\n u'productionYears': [],\n u'transmission': u'16 traction motors powered by four  generators'}\n{u'_id': ObjectId('59e6210a46106039a8438a02'),\n u'class': u'land speed record',\n u'designer': [u'Glynne_Bowsher', u'Jeremy_Bliss', u'Ron Ayers'],\n u'dimensions': {u'length': 16.5, u'width': 3.7},\n u'modelYears': [],\n u'name': u'Thrust SSC',\n u'productionYears': []}\n{u'_id': ObjectId('59e6210a46106039a8439346'),\n u'assembly': [u'Newport News Virginia', u'United States'],\n u'bodyStyle': u'dump truck',\n u'class': u'haul truck',\n u'dimensions': {u'height': 7.4,\n                 u'length': 14.5,\n                 u'wheelbase': 6.4008,\n                 u'width': 8.7},\n u'engine': [u'Liebherr_T_282B__2',\n             u'Liebherr_T_282B__3',\n             u'Liebherr_T_282B__4',\n             u'Liebherr_T_282B__8',\n             u'Liebherr_T_282B__9'],\n u'layout': u'automobile layout',\n u'modelYears': [],\n u'name': u'Liebherr T 282B',\n u'productionYears': [],\n u'transmission': u'AC electric'}\n"
     ]
    }
   ],
   "source": [
    "# 练习: 点表示法\n",
    "# 题目说明\n",
    "# 你的任务是写一个查询，返回宽度大于 2.5 的所有汽车。只需修改 dot_query 函数，因为我们仅对该函数进行评分。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。\n",
    "# \n",
    "# 如果你想在本地机器上运行代码，你需要安装 MongoDB 并下载和插入数据集。\n",
    "# \n",
    "# 要了解 MongoDB 设置和数据集方面的说明，请参阅课程资料。\n",
    "\n",
    "def dot_query():\n",
    "    # Edit the line below with your query - try to use dot notation.\n",
    "    # You can check out example_auto.txt for an example of the document\n",
    "    # structure in the collection.\n",
    "    query = {'dimensions.width':{\"$gt\":2.5}}\n",
    "    return query\n",
    "\n",
    "\n",
    "# Do not edit code below this line in the online code editor.\n",
    "# Code here is for local use on your own computer.\n",
    "def get_db():\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client.examples\n",
    "    return db\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    db = get_db()\n",
    "    query = dot_query()\n",
    "    cars = db.autos.find(query)\n",
    "\n",
    "    print \"Printing first 3 results\\n\"\n",
    "    import pprint\n",
    "    for car in cars[:3]:\n",
    "        pprint.pprint(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your first entry:\n{'classification': {'class': 'Arachnid',\n                    'family': 'Orb-weaver spider',\n                    'genus': None,\n                    'kingdom': 'Animal',\n                    'order': 'Spider',\n                    'phylum': 'Arthropod'},\n 'description': 'The genus Argiope includes rather large and spectacular spiders that often have a strikingly coloured abdomen. These spiders are distributed throughout the world. Most countries in tropical or temperate climates host one or more species that are similar in appearance. The etymology of the name is from a Greek name meaning silver-faced.',\n 'label': 'Argiope',\n 'name': 'Argiope',\n 'synonym': None,\n 'uri': 'http://dbpedia.org/resource/Argiope_(spider)'}\nArgiope :  Argiope\n"
     ]
    }
   ],
   "source": [
    "# 练习: 准备数据\n",
    "# 问题描述\n",
    "# 在此习题集中，你将处理另一种类型的 infobox 数据，审核、清理数据，并得出一种数据模型，将数据插入 MongoDB，然后对数据库运行一些查询。数据集中包含关于蛛形纲动物的数据。\n",
    "# \n",
    "# 对于这道练习，你的任务是解析文件，仅处理 FIELDS 字典中作为键的字段，并返回清理后的值字典列表。\n",
    "# \n",
    "# 你应该完成以下几个步骤：\n",
    "# \n",
    "# 根据 FIELDS 字典中的映射更改字典的键\n",
    "# 删掉“rdf-schema#label”中的小括号里的多余说明，例如“(spider)”\n",
    "# 如果“name”为“NULL”，或包含非字母数字字符，将其设为和“label”相同的值。\n",
    "# 如果字段的值为“NULL”，将其转换为“None”\n",
    "# 如果“synonym”中存在值，应将其转换为数组（列表），方法是删掉“{}”字符，并根据“|” 拆分字符串。剩下的清理方式将由你自行决定，例如删除前缀“*”等。如果存在单数同义词，值应该依然是列表格式。\n",
    "# 删掉所有字段前后的空格（如果有的话）\n",
    "# 输出结构应该如下所示：\n",
    "# [ { 'label': 'Argiope',\n",
    "#     'uri': 'http://dbpedia.org/resource/Argiope_(spider)',\n",
    "#     'description': 'The genus Argiope includes rather large and spectacular spiders that often ...',\n",
    "#     'name': 'Argiope',\n",
    "#     'synonym': [\"One\", \"Two\"],\n",
    "#     'classification': {\n",
    "#                       'family': 'Orb-weaver spider',\n",
    "#                       'class': 'Arachnid',\n",
    "#                       'phylum': 'Arthropod',\n",
    "#                       'order': 'Spider',\n",
    "#                       'kingdom': 'Animal',\n",
    "#                       'genus': None\n",
    "#                       }\n",
    "#   },\n",
    "#   { 'label': ... , }, ...\n",
    "# ]\n",
    "\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "DATAFILE = 'arachnid.csv'\n",
    "FIELDS ={'rdf-schema#label': 'label',\n",
    "         'URI': 'uri',\n",
    "         'rdf-schema#comment': 'description',\n",
    "         'synonym': 'synonym',\n",
    "         'name': 'name',\n",
    "         'family_label': 'family',\n",
    "         'class_label': 'class',\n",
    "         'phylum_label': 'phylum',\n",
    "         'order_label': 'order',\n",
    "         'kingdom_label': 'kingdom',\n",
    "         'genus_label': 'genus'}\n",
    "\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "def process_file_2(filename, fields):\n",
    "\n",
    "    process_fields = fields.keys()\n",
    "    classification_keys = [\"kingdom\",\"family\",\"order\",\"phylum\",\"genus\",\"class\"]\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        \n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "\n",
    "        for line in reader:\n",
    "            classification = {}\n",
    "            new_line = {\"classification\":classification}\n",
    "            \n",
    "            for filed in process_fields:\n",
    "                \n",
    "                if line[filed] == 'NULL':\n",
    "                    line[filed] = None\n",
    "                else:\n",
    "                    line[filed] = line[filed].rstrip()\n",
    "                   \n",
    "                    \n",
    "                if fields[filed] in classification_keys:\n",
    "                    \n",
    "                    classification[fields[filed]] = line[filed] \n",
    "                   \n",
    "                else:\n",
    "                    new_line[fields[filed]] = line[filed] \n",
    "            \n",
    "            label = new_line['label']\n",
    "            \n",
    "            if label.find('(') != -1 and label.find(')')!= -1:\n",
    "                new_line[\"label\"] = re.sub('(\\([^\\)]+\\))','',label)\n",
    "                new_line[\"label\"] = new_line[\"label\"].rstrip()\n",
    "            name = new_line['name']\n",
    "            if name != None and problemchars.search(name): \n",
    "                new_line['name'] = new_line['label']\n",
    "                \n",
    "            synonym = new_line['synonym']\n",
    "                \n",
    "            if synonym != None:\n",
    "                \n",
    "                if synonym.find('*') != -1:\n",
    "                    synonym = str.replace(synonym,'*','')\n",
    "                new_line['synonym'] = parse_array(synonym)\n",
    "        \n",
    "            \n",
    "            data.append(new_line)\n",
    "            \n",
    "            pass\n",
    "   \n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_array(v):\n",
    "    if (v[0] == \"{\") and (v[-1] == \"}\"):\n",
    "        v = v.lstrip(\"{\")\n",
    "        v = v.rstrip(\"}\")\n",
    "        v_array = v.split(\"|\")\n",
    "        v_array = [i.strip() for i in v_array]\n",
    "        return v_array\n",
    "    return [v]\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = process_file_2(DATAFILE, FIELDS)\n",
    "    print \"Your first entry:\"\n",
    "    pprint.pprint(data[0])\n",
    "    first_entry = {\n",
    "        \"synonym\": None, \n",
    "        \"name\": \"Argiope\", \n",
    "        \"classification\": {\n",
    "            \"kingdom\": \"Animal\", \n",
    "            \"family\": \"Orb-weaver spider\", \n",
    "            \"order\": \"Spider\", \n",
    "            \"phylum\": \"Arthropod\", \n",
    "            \"genus\": None, \n",
    "            \"class\": \"Arachnid\"\n",
    "        }, \n",
    "        \"uri\": \"http://dbpedia.org/resource/Argiope_(spider)\", \n",
    "        \"label\": \"Argiope\", \n",
    "        \"description\": \"The genus Argiope includes rather large and spectacular spiders that often have a strikingly coloured abdomen. These spiders are distributed throughout the world. Most countries in tropical or temperate climates host one or more species that are similar in appearance. The etymology of the name is from a Greek name meaning silver-faced.\"\n",
    "    }\n",
    "\n",
    "    assert len(data) == 76\n",
    "    \n",
    "    print data[0]['label'],': ',first_entry['label'] \n",
    "\n",
    "    assert data[0] == first_entry\n",
    "    assert data[17][\"name\"] == \"Ogdenia\"\n",
    "    assert data[48][\"label\"] == \"Hydrachnidiae\"\n",
    "    assert data[14][\"synonym\"] == [\"Cyrene Peckham & Peckham\"]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n",
    "\n",
    "# process_file(DATAFILE,FIELDS) \n",
    "# d2 = {}\n",
    "# d1 = {'test':d2}\n",
    "# \n",
    "# d2['12'] = 33\n",
    "# \n",
    "# print d1\n",
    "# s1 = '  1234  '\n",
    "# \n",
    "# s1.rstrip()\n",
    "\n",
    "\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n{u'synonym': None, u'description': u'The genus Argiope includes rather large and spectacular spiders that often have a strikingly coloured abdomen. These spiders are distributed throughout the world. Most countries in tropical or temperate climates host one or more species that are similar in appearance. The etymology of the name is from a Greek name meaning silver-faced.', u'classification': {u'kingdom': u'Animal', u'family': u'Orb-weaver spider', u'order': u'Spider', u'phylum': u'Arthropod', u'genus': None, u'class': u'Arachnid'}, u'uri': u'http://dbpedia.org/resource/Argiope_(spider)', u'label': u'Argiope', u'_id': ObjectId('59e76fa546106039a843a83f'), u'name': u'Argiope'}\n"
     ]
    }
   ],
   "source": [
    "# 练习: 向 MongoDB 插入数据\n",
    "# 问题描述\n",
    "# 完成 insert_data 函数，将数据插入 MongoDB。\n",
    "\n",
    "import json\n",
    "from json import dumps as json_dump\n",
    "datafile = process_file_2(DATAFILE,FIELDS)\n",
    "# jsonString = json.dumps(datafile,ensure_ascii=False).encode('utf-8')\n",
    "# jsonString = json_dump(datafile,ensure_ascii=False)\n",
    "# print jsonString\n",
    "def insert_data(data, db):\n",
    "   \n",
    "    # Your code here. Insert the data into a collection 'arachnid'\n",
    "    db.arachnid.insert_many(data)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient(\"mongodb://localhost:27017\")\n",
    "    db = client.examples\n",
    "    db.arachnid.insert_many(datafile)\n",
    "    # with open(datafile) as f:\n",
    "    #     data = json.loads(f.read())\n",
    "    #     # insert_data(data, db)\n",
    "    print db.arachnid.find().count()\n",
    "    print db.arachnid.find_one()\n",
    "\n",
    "# from pymongo import MongoClient\n",
    "# client = MongoClient(\"mongodb://localhost:27017\")\n",
    "# db = client.examples\n",
    "# \n",
    "# db.test.insert_many(datafile)\n",
    "# print db.test.find_one()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习: 使用组\n",
    "# 问题描述\n",
    "# 我们的推特集合中的推特有一个叫做“source”的字段。该字段描述了用来创建推特的应用。在使用 $group 运算符的示例之后，你的任务是修改“make-pipeline”函数，找到创建推特时最常用的应用。为了检验你的查询，“网络浏览器”是最常用的应用。“Ubertwitter”是第二大常用的应用。数量应该存储在叫做“count”的字段中 （请参阅脚本最后的声明）。\n",
    "# \n",
    "# 只需修改“make_pipeline”函数，使其创建并返回一个聚合管道，该管道可以传递到 MongoDB 聚合函数中。和这节课中的示例一样，聚合管道应该是一个包含一个或多个字典对象的列表。如果不熟悉语法，请参阅这节课中的示例。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。\n",
    "# \n",
    "# 如果你想在本地机器上运行代码，你需要安装 MongoDB 并下载和插入数据集。要了解 MongoDB 设置和数据集方面的说明，请参阅课程资料。\n",
    "# \n",
    "# 请注意，你在此处使用的数据集是这节课的示例中使用的推特数据集的简略版本。如果你尝试运行我们在课程示例中运行过的同一查询，结果可能不同。\n",
    "# $group 聚合运算符文档。\n",
    "# \n",
    "# 注意：在当前版本的 pymongo (3.0) 中，聚合运算返回的是游标对象。为了看到所返回的元素，你可以在游标对象上进行迭代（比如使用 for 循环），并逐个输出元素。在本地计算机上操作时，请记住这一点。\n",
    "# \n",
    "# 示例推文：\n",
    "# \n",
    "# {\n",
    "#     \"_id\" : ObjectId(\"5304e2e3cc9e684aa98bef97\"),\n",
    "#     \"text\" : \"First week of school is over :P\",\n",
    "#     \"in_reply_to_status_id\" : null,\n",
    "#     \"retweet_count\" : null,\n",
    "#     \"contributors\" : null,\n",
    "#     \"created_at\" : \"Thu Sep 02 18:11:25 +0000 2010\",\n",
    "#     \"geo\" : null,\n",
    "#     \"source\" : \"web\",\n",
    "#     \"coordinates\" : null,\n",
    "#     \"in_reply_to_screen_name\" : null,\n",
    "#     \"truncated\" : false,\n",
    "#     \"entities\" : {\n",
    "#         \"user_mentions\" : [ ],\n",
    "#         \"urls\" : [ ],\n",
    "#         \"hashtags\" : [ ]\n",
    "#     },\n",
    "#     \"retweeted\" : false,\n",
    "#     \"place\" : null,\n",
    "#     \"user\" : {\n",
    "#         \"friends_count\" : 145,\n",
    "#         \"profile_sidebar_fill_color\" : \"E5507E\",\n",
    "#         \"location\" : \"Ireland :)\",\n",
    "#         \"verified\" : false,\n",
    "#         \"follow_request_sent\" : null,\n",
    "#         \"favourites_count\" : 1,\n",
    "#         \"profile_sidebar_border_color\" : \"CC3366\",\n",
    "#         \"profile_image_url\" : \"http://a1.twimg.com/profile_images/1107778717/phpkHoxzmAM_normal.jpg\",\n",
    "#         \"geo_enabled\" : false,\n",
    "#         \"created_at\" : \"Sun May 03 19:51:04 +0000 2009\",\n",
    "#         \"description\" : \"\",\n",
    "#         \"time_zone\" : null,\n",
    "#         \"url\" : null,\n",
    "#         \"screen_name\" : \"Catherinemull\",\n",
    "#         \"notifications\" : null,\n",
    "#         \"profile_background_color\" : \"FF6699\",\n",
    "#         \"listed_count\" : 77,\n",
    "#         \"lang\" : \"en\",\n",
    "#         \"profile_background_image_url\" : \"http://a3.twimg.com/profile_background_images/138228501/149174881-8cd806890274b828ed56598091c84e71_4c6fd4d8-full.jpg\",\n",
    "#         \"statuses_count\" : 2475,\n",
    "#         \"following\" : null,\n",
    "#         \"profile_text_color\" : \"362720\",\n",
    "#         \"protected\" : false,\n",
    "#         \"show_all_inline_media\" : false,\n",
    "#         \"profile_background_tile\" : true,\n",
    "#         \"name\" : \"Catherine Mullane\",\n",
    "#         \"contributors_enabled\" : false,\n",
    "#         \"profile_link_color\" : \"B40B43\",\n",
    "#         \"followers_count\" : 169,\n",
    "#         \"id\" : 37486277,\n",
    "#         \"profile_use_background_image\" : true,\n",
    "#         \"utc_offset\" : null\n",
    "#     },\n",
    "#     \"favorited\" : false,\n",
    "#     \"in_reply_to_user_id\" : null,\n",
    "#     \"id\" : NumberLong(\"22819398300\")\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{\"$group\":{\"_id\":\"$source\",\"count\":{\"$sum\":1}}},{\"$sort\":{\"count\":-1}}]\n",
    "    return pipeline\n",
    "\n",
    "def tweet_sources(db, pipeline):\n",
    "    return [doc for doc in db.tweets.aggregate(pipeline)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('twitter')\n",
    "    pipeline = make_pipeline()\n",
    "    result = tweet_sources(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result[0])\n",
    "    assert result[0] == {u'count': 868, u'_id': u'web'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习: 使用 Match 和 Project 运算符\n",
    "# 问题描述\n",
    "# 写一个回答以下问题的聚合查询：\n",
    "# \n",
    "# 对于巴西利亚时区的用户，哪些用户发推次数不低于 100 次，哪些用户的关注者数量最多？\n",
    "# \n",
    "# 以下提示将帮助你解决这一问题：\n",
    "# \n",
    "# 你可以在每个推特的用户对象的“time_zone”字段中找到时区。\n",
    "# 你可以在“statuses_count”字段中找到每个用户的发推数量。\n",
    "# 注意，你需要创建“followers”、“screen_name”和“tweets”字段。\n",
    "# \n",
    "# 只需修改“make_pipeline”函数，使其创建并返回一个聚合管道，该管道可以传递到 MongoDB 聚合函数中。和这节课中的示例一样，聚合管道应该是一个包含一个或多个字典对象的列表。如果不熟悉语法，请参阅这节课中的示例。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。如果你想在本地机器上运行代码，你需要安装 MongoDB 并下载和插入数据集。要了解 MongoDB 设置和数据集方面的说明，请参阅课程资料。\n",
    "# \n",
    "# 请注意，你在此处使用的数据集是这节课的示例中使用的推特数据集的简略版本。如果你尝试运行我们在课程示例中运行过的同一查询，结果可能不同。\n",
    "# 聚合框架运算符文档\n",
    "# \n",
    "# 注意：在当前版本的 pymongo (3.0) 中，聚合运算返回的是游标对象。为了看到所返回的元素，你可以在游标对象上进行迭代（比如使用 for 循环），并逐个输出元素。在本地计算机上操作时，请记住这一点。\n",
    "# \n",
    "# 示例推文：\n",
    "# \n",
    "# {\n",
    "#     \"_id\" : ObjectId(\"5304e2e3cc9e684aa98bef97\"),\n",
    "#     \"text\" : \"First week of school is over :P\",\n",
    "#     \"in_reply_to_status_id\" : null,\n",
    "#     \"retweet_count\" : null,\n",
    "#     \"contributors\" : null,\n",
    "#     \"created_at\" : \"Thu Sep 02 18:11:25 +0000 2010\",\n",
    "#     \"geo\" : null,\n",
    "#     \"source\" : \"web\",\n",
    "#     \"coordinates\" : null,\n",
    "#     \"in_reply_to_screen_name\" : null,\n",
    "#     \"truncated\" : false,\n",
    "#     \"entities\" : {\n",
    "#         \"user_mentions\" : [ ],\n",
    "#         \"urls\" : [ ],\n",
    "#         \"hashtags\" : [ ]\n",
    "#     },\n",
    "#     \"retweeted\" : false,\n",
    "#     \"place\" : null,\n",
    "#     \"user\" : {\n",
    "#         \"friends_count\" : 145,\n",
    "#         \"profile_sidebar_fill_color\" : \"E5507E\",\n",
    "#         \"location\" : \"Ireland :)\",\n",
    "#         \"verified\" : false,\n",
    "#         \"follow_request_sent\" : null,\n",
    "#         \"favourites_count\" : 1,\n",
    "#         \"profile_sidebar_border_color\" : \"CC3366\",\n",
    "#         \"profile_image_url\" : \"http://a1.twimg.com/profile_images/1107778717/phpkHoxzmAM_normal.jpg\",\n",
    "#         \"geo_enabled\" : false,\n",
    "#         \"created_at\" : \"Sun May 03 19:51:04 +0000 2009\",\n",
    "#         \"description\" : \"\",\n",
    "#         \"time_zone\" : null,\n",
    "#         \"url\" : null,\n",
    "#         \"screen_name\" : \"Catherinemull\",\n",
    "#         \"notifications\" : null,\n",
    "#         \"profile_background_color\" : \"FF6699\",\n",
    "#         \"listed_count\" : 77,\n",
    "#         \"lang\" : \"en\",\n",
    "#         \"profile_background_image_url\" : \"http://a3.twimg.com/profile_background_images/138228501/149174881-8cd806890274b828ed56598091c84e71_4c6fd4d8-full.jpg\",\n",
    "#         \"statuses_count\" : 2475,\n",
    "#         \"following\" : null,\n",
    "#         \"profile_text_color\" : \"362720\",\n",
    "#         \"protected\" : false,\n",
    "#         \"show_all_inline_media\" : false,\n",
    "#         \"profile_background_tile\" : true,\n",
    "#         \"name\" : \"Catherine Mullane\",\n",
    "#         \"contributors_enabled\" : false,\n",
    "#         \"profile_link_color\" : \"B40B43\",\n",
    "#         \"followers_count\" : 169,\n",
    "#         \"id\" : 37486277,\n",
    "#         \"profile_use_background_image\" : true,\n",
    "#         \"utc_offset\" : null\n",
    "#     },\n",
    "#     \"favorited\" : false,\n",
    "#     \"in_reply_to_user_id\" : null,\n",
    "#     \"id\" : NumberLong(\"22819398300\")\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'$match': {'user.statuses_count': {'$gte': 100},\n   'user.time_zone': {'$eq': 'Brasilia'}}},\n {'$project': {'followers': '$user.followers_count',\n   'screen_name': '$user.screen_name',\n   'tweets': '$user.statuses_count'}},\n {'$sort': {'followers': -1}},\n {'$limit': 1}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "        {\"$match\":{\"user.time_zone\":{\"$eq\":\"Brasilia\"}, \"user.statuses_count\":{\"$gte\":100}}},\n",
    "        {\"$project\":{\"followers\": \"$user.followers_count\" ,\"screen_name\":\"$user.screen_name\",\n",
    "    \"tweets\":\"$user.statuses_count\"}},\n",
    "         {\"$sort\" : {\"followers\":-1}},\n",
    "        {\"$limit\": 1}\n",
    "        ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.tweets.aggregate(pipeline)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('twitter')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result)\n",
    "    assert len(result) == 1\n",
    "    assert result[0][\"followers\"] == 17209\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习: 使用 Unwind 运算符\n",
    "# 问题描述\n",
    "# 对于这道练习，我们回到城市 infobox 数据集。我们希望你能回答以下问题：印度的哪个地区包括的城市最多？\n",
    "# （确保将城市计数存储在叫做“count”的字段中；请参阅脚本末尾的声明。）\n",
    "# \n",
    "# 首先，使用我们提出的以下示例问题的答案：谁在推特中提到的用户数最多？\n",
    "# \n",
    "# 对于城市数据，需要注意的一点是：“isPartOf”字段包含一个地区数组，可以在其中查找城市。\n",
    "# 请参阅下面的讲师注释中的示例文档。\n",
    "# \n",
    "# 只需修改“make_pipeline”函数，使其创建并返回一个聚合管道，该管道可以传递到 MongoDB 聚合函数中。\n",
    "# 和这节课中的示例一样，聚合管道应该是一个包含一个或多个字典对象的列表。如果不熟悉语法，请参阅这节课中的示例。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。如果你想在本地机器上运行代码，你需要安装 MongoDB 并下载和插入数据集。\n",
    "# 要了解 MongoDB 设置和数据集方面的说明，请参阅课程资料。\n",
    "# \n",
    "# 请注意，你在此处使用的数据集是这节课的示例中使用的城市集合的简略版本。\n",
    "# 如果你尝试运行我们在课程示例中运行过的同一查询，结果可能不同。\n",
    "# 管道聚合运算符文档\n",
    "# \n",
    "# 注意：在当前版本的 pymongo (3.0) 中，聚合运算返回的是游标对象。为了看到所返回的元素，\n",
    "# 你可以在游标对象上进行迭代（比如使用 for 循环），并逐个输出元素。在本地计算机上操作时，请记住这一点。\n",
    "# \n",
    "# 这是一个示例文档：\n",
    "# \n",
    "# {\n",
    "#     \"_id\" : ObjectId(\"52fe1d364b5ab856eea75ebc\"),\n",
    "#     \"elevation\" : 1855,\n",
    "#     \"name\" : \"Kud\",\n",
    "#     \"country\" : \"India\",\n",
    "#     \"lon\" : 75.28,\n",
    "#     \"lat\" : 33.08,\n",
    "#     \"isPartOf\" : [\n",
    "#         \"Jammu and Kashmir\",\n",
    "#         \"Udhampur district\"\n",
    "#     ],\n",
    "#     \"timeZone\" : [\n",
    "#         \"Indian Standard Time\"\n",
    "#     ],\n",
    "#     \"population\" : 1140\n",
    "# }\n",
    "# 提示：别忘了，在创建管道时，我们只关注印度地区。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "        {\"$match\":{\"country\":{\"$eq\":\"India\"}}},\n",
    "        {\"$unwind\":\"$isPartOf\"},\n",
    "        {\"$group\":{\"_id\":\"$isPartOf\",\"count\":{\"$sum\":1}}},\n",
    "        {\"$sort\":{\"count\":-1}},\n",
    "        {\"$limit\": 1}\n",
    "    ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.cities.aggregate(pipeline)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('examples')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    print \"Printing the first result:\"\n",
    "    import pprint\n",
    "    pprint.pprint(result[0])\n",
    "    assert result[0][\"_id\"] == \"Uttar Pradesh\"\n",
    "    assert result[0][\"count\"] == 623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习: 使用推送\n",
    "# 问题描述\n",
    "# $push 与 $addToSet 相似。区别在于 $push 会将所有值（而不是唯一值）整合到数组中。\n",
    "# \n",
    "# 通过聚合查询查找出每个用户的推特数量。在相同的 $group 阶段，使用 $push 数出每个用户的所有推特文本数量。\n",
    "# 仅数出推特数量在前五名的用户。\n",
    "# \n",
    "# 最后的文档应该仅包含以下字段：\n",
    "# \n",
    "# \"_id\"（用户的帐号名）， \n",
    "# \"count\"（用户的推文数量），\n",
    "# \"tweet_texts\"（用户的推文列表）。\n",
    "# \n",
    "# 只需修改“make_pipeline”函数，使其创建并返回一个聚合管道，该管道可以传递到 MongoDB 聚合函数中。\n",
    "# 和这节课中的示例一样，聚合管道应该是一个包含一个或多个字典对象的列表。如果不熟悉语法，请参阅这节课中的示例。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。如果你想在本地机器上运行代码，你需要安装 MongoDB 并下载和插入数据集。\n",
    "# 要了解 MongoDB 设置和数据集方面的说明，请参阅课程资料。\n",
    "# \n",
    "# 请注意，你在此处使用的数据集是这节课的示例中使用的推特数据集的简略版本。\n",
    "# 如果你尝试运行我们在课程示例中运行过的同一查询，结果可能不同。\n",
    "\n",
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "        {\"$group\":{\"_id\":\"$user.screen_name\",\"count\":{\"$sum\":1},\n",
    "         \"tweet_texts\":{\"$push\":\"$text\"}}},\n",
    "        {\"$sort\":{\"count\":-1}},\n",
    "        {\"$limit\": 5}\n",
    "        \n",
    "    ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.twitter.aggregate(pipeline)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('twitter')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result)\n",
    "    assert len(result) == 5\n",
    "    assert result[0][\"count\"] > result[4][\"count\"]\n",
    "    sample_tweet_text = u'Take my money! #liesguystell http://movie.sras2.ayorganes.com'\n",
    "    assert result[4][\"tweet_texts\"][0] == sample_tweet_text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习: Same 运算符\n",
    "# 问题描述\n",
    "# 在上一道练习中，我们查看了城市数据集，并询问印度的哪个地区包含的城市最多。在这道练习中，\n",
    "# 我们想请你回答另一个关于印度地区的相关问题。印度各个地区的平均人口数量是多少？\n",
    "# 你需要首先计算每个地区城市的平均人口数量，然后计算地区的平均人口数量。\n",
    "# \n",
    "# 提示：如果你想使用所有输入文档中的值汇集到一个群组阶段中，可以使用常量作为“_id”字段的值。例如：\n",
    "# { \"$group\" : {\"_id\" : \"India Regional City Population Average\", ... }\n",
    "# \n",
    "# 只需修改“make_pipeline”函数，使其创建并返回一个聚合管道，该管道可以传递到 MongoDB 聚合函数中。\n",
    "# 和这节课中的示例一样，聚合管道应该是一个包含一个或多个字典对象的列表。如果不熟悉语法，请参阅这节课中的示例。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。如果你想在本地机器上运行代码，\n",
    "# 你需要安装 MongoDB 并下载和插入数据集。要了解 MongoDB 设置和数据集方面的说明，请参阅课程资料。\n",
    "# \n",
    "# 请注意，你在此处使用的数据集是这节课的示例中使用的推特数据集的简略版本。\n",
    "# 如果你尝试运行我们在课程示例中运行过的同一查询，结果可能不同。\n",
    "# MongoDb 运算符文档\n",
    "# \n",
    "# 注意：在当前版本的 pymongo (3.0) 中，聚合运算返回的是游标对象。为了看到所返回的元素，\n",
    "# 你可以在游标对象上进行迭代（比如使用 for 循环），并逐个输出元素。在本地计算机上操作时，请记住这一点。\n",
    "# \n",
    "# 这是一个示例文档：\n",
    "# \n",
    "# {\n",
    "#     \"_id\" : ObjectId(\"52fe1d364b5ab856eea75ebc\"),\n",
    "#     \"elevation\" : 1855,\n",
    "#     \"name\" : \"Kud\",\n",
    "#     \"country\" : \"India\",\n",
    "#     \"lon\" : 75.28,\n",
    "#     \"lat\" : 33.08,\n",
    "#     \"isPartOf\" : [\n",
    "#         \"Jammu and Kashmir\",\n",
    "#         \"Udhampur district\"\n",
    "#     ],\n",
    "#     \"timeZone\" : [\n",
    "#         \"Indian Standard Time\"\n",
    "#     ],\n",
    "#     \"population\" : 1140\n",
    "# }\n",
    "\n",
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [\n",
    "        {\"$match\":{\"country\":{\"$eq\":\"India\"}}},\n",
    "        {\"$unwind\":\"$isPartOf\"},\n",
    "        {\"$group\":{\"_id\":\"$isPartOf\",\"population_region\":{\"$avg\":\"$population\"}}},\n",
    "        {\"$group\":{\"_id\":\"reg_avg\",\"avg\":{\"$avg\":\"$population_region\"}}}\n",
    " \n",
    "        \n",
    "    ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.cities.aggregate(pipeline)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('examples')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    assert len(result) == 1\n",
    "    # Your result should be close to the value after the minus sign.\n",
    "    assert abs(result[0][\"avg\"] - 201128.0241546919) < 10 ** -8\n",
    "    import pprint\n",
    "    pprint.pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationFailure",
     "evalue": "unknown top level operator: $name",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mOperationFailure\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-7bdef84cb552>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_db\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-7bdef84cb552>\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(db, pipeline)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcities\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lk235\\Anaconda2\\lib\\site-packages\\pymongo\\collection.pyc\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, pipeline, **kwargs)\u001b[0m\n\u001b[0;32m   1916\u001b[0m                     result = self._command(sock_info, cmd, slave_ok,\n\u001b[0;32m   1917\u001b[0m                                            \u001b[0mread_concern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_concern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m                                            collation=collation)\n\u001b[0m\u001b[0;32m   1919\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m                 result = self._command(sock_info, cmd, slave_ok,\n",
      "\u001b[1;32mC:\\Users\\lk235\\Anaconda2\\lib\\site-packages\\pymongo\\collection.pyc\u001b[0m in \u001b[0;36m_command\u001b[1;34m(self, sock_info, command, slave_ok, read_preference, codec_options, check, allowable_errors, read_concern, write_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mwrite_concern\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m             \u001b[0mparse_write_concern_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_write_concern_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             collation=collation)\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__create\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lk235\\Anaconda2\\lib\\site-packages\\pymongo\\pool.pyc\u001b[0m in \u001b[0;36mcommand\u001b[1;34m(self, dbname, spec, slave_ok, read_preference, codec_options, check, allowable_errors, check_keys, read_concern, write_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[0;32m    475\u001b[0m                            \u001b[0mread_concern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m                            \u001b[0mparse_write_concern_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_write_concern_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m                            collation=collation)\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lk235\\Anaconda2\\lib\\site-packages\\pymongo\\network.pyc\u001b[0m in \u001b[0;36mcommand\u001b[1;34m(sock, dbname, spec, slave_ok, is_mongos, read_preference, codec_options, check, allowable_errors, address, check_keys, listeners, max_bson_size, read_concern, parse_write_concern_error, collation)\u001b[0m\n\u001b[0;32m    114\u001b[0m             helpers._check_command_response(\n\u001b[0;32m    115\u001b[0m                 \u001b[0mresponse_doc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallowable_errors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m                 parse_write_concern_error=parse_write_concern_error)\n\u001b[0m\u001b[0;32m    117\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpublish\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\lk235\\Anaconda2\\lib\\site-packages\\pymongo\\helpers.pyc\u001b[0m in \u001b[0;36m_check_command_response\u001b[1;34m(response, msg, allowable_errors, parse_write_concern_error)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"%s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOperationFailure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationFailure\u001b[0m: unknown top level operator: $name"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# 练习: 最常见的城市名\n",
    "# 问题描述\n",
    "# 请使用聚合查询回答以下问题。\n",
    "# \n",
    "# 我们的城市集合中最常用的城市名称是什么？\n",
    "# \n",
    "# 你一开始可能会发现 None 是最常出现的城市名称。实际上表示很多城市根本没有名称字段。\n",
    "# 很奇怪此集合中会出现此类文档，根据你的具体情况，你可能需要进一步清理数据。\n",
    "# \n",
    "# 要立即解答此问题，我们应该忽略没有指定名称的城市。提示下，可以思考哪个管道运算符使我们能够简化过滤器输入？\n",
    "# 我们如何测试某个字段是否存在？\n",
    "# \n",
    "# 只需修改“make_pipeline”函数，使其创建并返回一个聚合管道，该管道可以传递到 MongoDB 聚合函数中。\n",
    "# 和这节课中的示例一样，聚合管道应该是一个包含一个或多个字典对象的列表。如果不熟悉语法，请参阅这节课中的示例。\n",
    "# \n",
    "# 你的代码将根据我们提供的 MongoDB 实例运行。如果你想在本地机器上运行代码，\n",
    "# 你需要安装 MongoDB 并下载和插入数据集。要了解 MongoDB 设置和数据集方面的说明，请参阅课程资料。\n",
    "# \n",
    "# 请注意，你在此处使用的数据集与课程资料中提供的城市集合版本不同。\n",
    "# 如果你尝试运行我们在习题集中运行过的同一查询，结果可能不同。\n",
    "\n",
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{\"$match\":{$not: [ { [ \"$qty\", 250 ] } ]}},\n",
    "                {\"$group\":{\"_id\":\"$name\",\"count\":{\"$sum\":1}}},\n",
    "                {\"$sort\":{\"count\":-1}},\n",
    "                {\"$limit\": 50}]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.cities.aggregate(pipeline)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # The following statements will be used to test your code by the grader.\n",
    "    # Any modifications to the code past this point will not be reflected by\n",
    "    # the Test Run.\n",
    "\n",
    "    db = get_db('test')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result)\n",
    "#     assert len(result) == 1\n",
    "#     assert result[0] == {'_id': 'Shahpur', 'count': 6}\n",
    "\n",
    "# db = get_db('test')\n",
    "# db.cities.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
