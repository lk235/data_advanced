{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 动物园数据库中的所有表格\n",
    "# animals\n",
    "# 此表列出动物园中的各个动物。每只动物仅占一行。可能存在多只动物同名，甚至多只同物种动物同名的情况。\n",
    "# name — 动物的名字（例如：“George”）\n",
    "# species — 动物所属物种（例如：“gorilla”（大猩猩））\n",
    "# birthdate — 动物的出生日期（例如：'1998-05-18'）\n",
    "# diet\n",
    "# 此表对照列出各物种及其所吃的食物。动物园中的每个物种至少吃一种食物，许多物种吃多种食物。 如果某物种食用一种以上的食物，则该物种将占多行。\n",
    "# species — 物种名称（例如：“hyena”（鬣狗））\n",
    "# food — 物种所吃食物的名称（例如：“meat”（肉类））\n",
    "# taxonomy\n",
    "# 此表列出动物园中各物种的（部分）生物分类学名称。可用于辨别物种之间进化论角度的亲缘关系。\n",
    "# name — 物种的俗称（例如，“jackal”（豺））\n",
    "# species — 分类学物种名称（例如，“aureus”（亚洲胡狼））\n",
    "# genus — 分类学属名（例如，“Canis”（犬属））\n",
    "# family — 分类学科名（例如，“Canidae”（犬科））\n",
    "# t_order — 分类学目名（例如，“Carnivora”（食肉目））\n",
    "# 如果你对此分类一无所知，也无需担心，本课程不需要详细掌握这些信息。但如果你对此感到好奇，可查阅维基百科相关文章 分类学 及 生物分类。\n",
    "# \n",
    "# ordernames\n",
    "# 此表列出 taxonomy 表中各分类学目的俗称。\n",
    "# t_order — 分类学目名（例如，“Cetacea”（鲸目））\n",
    "# name — 俗称（例如，“whales and dolphins”（鲸和海豚））"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit 10 offset 10 从第11行开始显示10条数据\n",
    "# order by name,age 先 首先按姓名排序，然后在每个姓名中再按年龄排序\n",
    "# group by 只和count或sum这种聚合函数一起使用（可用as给求和列起名）\n",
    "\n",
    "# select count(*) as number ,species from animals group by species order by number\n",
    "# \"INSERT INTO animals (name,species,birthdate) values('123','opossums', '1999-1-1') ;\"\n",
    "# group by 后不能使用where，where作用在聚合之前的列\n",
    "# where 作用于源表，having作用于结果表，在group by后使用\n",
    "# SELECT food,count(*) as number from animals join diet on animals.species = diet.species group by food\n",
    "# having number = 1\n",
    "\n",
    "# SELECT ordernames.name,count(*) as number from taxonomy \n",
    "# join ordernames on taxonomy.t_order = ordernames.t_order\n",
    "# join animals on animals.species = taxonomy.species group by taxonomy.t_order\n",
    "# \n",
    "# SELECT Email, FirstName,LastName,Genre.name as Name\n",
    "#  \n",
    "# FROM (((Customer JOIN Invoice ON Customer.CustomerId  = Invoice.CustomerId) as Customer_Invoice\n",
    "# join InvoiceLine on Invoice.InvoiceId = InvoiceLine.InvoiceId) as Customer_Invoice_InvoiceLine\n",
    "# join Track on InvoiceLine.TrackId  = Track.TrackId ) as Customer_Invoice_InvoiceLine_Track \n",
    "# join Genre on Track.GenreId = Genre.GenreId  where Genre.name = 'Rock' group by email \n",
    "# order by email ;\n",
    "# \n",
    "# SELECT BillingCity, count(Invoice.InvoiceId) from ((Invoice join InvoiceLine on Invoice.InvoiceId = InvoiceLine.InvoiceId) as Invoice_InvoiceLine\n",
    "# join Track on InvoiceLine.TrackId  = Track.TrackId ) as Invoice_InvoiceLine_Track \n",
    "# join Genre on Track.GenreId = Genre.GenreId where BillingCountry = 'France' and\n",
    "# Genre.name = Punk  group by BillingCity order by count(Invoice.InvoiceId) desc;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 规范化表的规则：\n",
    "# 1.每行的列数相同。\n",
    "# 实际上，数据库系统的确不允许每行的列数不同。但如果列的内容有时为空 (null)，有时不为空，\n",
    "# 或者如果在一个字段中填入多个值，这实际上是违背了这一规则。\n",
    "# \n",
    "# 此处以动物园数据库中的 diet 表为例。我们没有将某一物种食用的多种食物填入该物种对应的一行中，\n",
    "# 而是将每种食物分别填入不同数据行。这样更便于执行聚合与比较操作。\n",
    "# \n",
    "# 2.存在唯一的键，行中所有内容均与键相关。\n",
    "# 键可以是一列，也可以是多列。甚至可以是整个行（例如 diet 表）。但表中没有重复的行。\n",
    "# \n",
    "# 更重要的是，存储非唯一数据（如人名）时，应使用唯一标识符（如序列号）加以区分。\n",
    "# 这样可以确保我们不会仅因两个人同名而将他们的成绩或违章停车罚单合并。\n",
    "# \n",
    "# 3.与键无关的数据属于其他表。\n",
    "# 以 items 表为例，该表中包含项目、项目位置及位置的街道地址。其中，地址不是与项目相关的数据，\n",
    "# 而是与位置相关。将其移至单独的表中既可节省空间，又能减少歧义，而且我们随时可以使用 join 命令重建原始表。\n",
    "# \n",
    "# 4.表中不应隐含不存在的关系。\n",
    "# 以 job_skills 表为例，某人的一项技术技能（如“Linux”）及一项语言技能（如“French”（法语））\n",
    "# 在一个数据行中列出。这样看起来似乎 Linux 知识限于法语（或者反之），而实际并非如此。\n",
    "# 规范化过程需要将技术技能与职业技能拆分到不同的表中。\n",
    "\n",
    "# 声明关系:关联约束 referce 带关联约束的列也被称为外键\n",
    "# \n",
    "# 自连接：\n",
    "# select a.id, b.id, a.building, a.room\n",
    "#        from residences as a, residences as b\n",
    "#  where a.building = b.building\n",
    "#    and a.room = b.room and a.id < b.id \n",
    "#  order by a.building, a.room;\n",
    "# \n",
    "# 但有一种方法可以让数据库显示零计数。为此，我们需要对此查询做两处改动 —\n",
    "# \n",
    "# select products.name, products.sku, count(sales.sku) as num\n",
    "#   from products left join sales\n",
    "#     on products.sku = sales.sku\n",
    "#   group by products.sku;\n",
    "# 此查询将为 products 表中的每个产品返回一行，即使产品在 sales 表中没有销售记录亦是如此。\n",
    "# \n",
    "# 究竟做了怎样的改动呢？首先，我们用 count(sales.sku) 代替了 count(*)。这意味着数据库仅对定义了\n",
    "# sales.sku 的行（而非所有行）进行计数。\n",
    "# \n",
    "# 其次，我们用 left join 代替了 join。\n",
    "# \n",
    "# 什么是 left join（左连接）？\n",
    "# SQL 支持多种连接类型。本课程前面部分提到的连接称为 inner join（内连接），这是最常用的连接类型。\n",
    "# 在 SQL 中，连接默认指的就是内连接，不需特别说明。\n",
    "# \n",
    "# 其次常用的是 left join（左连接）及其镜像伙伴 right join（右连接）。\n",
    "# “左”和“右”分别指连接运算符左侧和右侧的表。（在上例中，左侧的表是 products，右侧的表是 sales。）\n",
    "# \n",
    "# 常规（内）连接仅返回符合连接条件的两表共有条目的数据行。left join 则不仅返回这些行，\n",
    "# 还返回左侧表中有条目、但右侧表不存在的行。right join 同理，但用于右侧表。\n",
    "# \n",
    "# （就像“join”实际是“inner join”的简称一样，“left join”实际是“left outer join”的简称。\n",
    "# 但在 SQL 中直接输入“left join”即可，\n",
    "# 这样可减少键盘操作。我们不妨就这样做。）\n",
    "# \n",
    "# 注意事项：在 count 聚合函数中放入哪些参数？如果保留 count(*) 不变或者将 programs 表中的某一列作为其参数，\n",
    "# 查询将对有缺陷和无缺陷的程序进行计数。\n",
    "# \n",
    "# 要为在 bugs 表中没有任何条目的程序报告零值，则必须将 bugs 表中的列作为 count 的参数。\n",
    "# 例如，count(bugs.filename) 和 count(bugs.description) 均具有此作用。\n",
    "# \n",
    "# SQL的语法要求对子查询结果表格进行命名\n",
    "# 视图相当于函数，可以在有很多列的表格中只显示特定的几列\n",
    "# \n",
    "# CREATE TABLE Album\n",
    "# (\n",
    "#     AlbumId INTEGER PRIMARY KEY,\n",
    "#     Title TEXT,\n",
    "#     ArtistId INTEGER,\n",
    "#     FOREIGN KEY (ArtistId) REFERENCES Artist (ArtistId) \n",
    "# );\n",
    "# \n",
    "# CREATE TABLE InvoiceLine\n",
    "# (\n",
    "#     InvoiceLineId INTEGER PRIMARY KEY,\n",
    "#     InvoiceId INTEGER,\n",
    "#     TrackId INTEGER,\n",
    "#     UnitPrice REAL,\n",
    "#     Quantity INTEGER,\n",
    "#     FOREIGN KEY (InvoiceId) REFERENCES Invoice (InvoiceId),\n",
    "#     FOREIGN KEY (TrackId) REFERENCES Track (TrackId)\n",
    "#     \n",
    "# );\n",
    "# \n",
    "# 将数据库中的数据导出为 CSV 文件\n",
    "# sqlite> .mode csv\n",
    "# sqlite> .output newFile.csv\n",
    "# sqlite> SELECT * FROM myTable;\n",
    "# sqlite> .exit\n",
    "# \n",
    "# 将 CSV 文件导入表中\n",
    "# $ sqlite3 new.db   <--- 如果要将 csv 文件导入新数据库中，切记要先创建该数据库。\n",
    "# \n",
    "# sqlite> CREATE TABLE myTable() <--- 构建您的模式！\n",
    "# sqlite> .mode csv\n",
    "# sqlite> .import newFile.csv myTable\n",
    "# 这种方法的使用有一些限制。 SQLite 并非无所不能，但却是一个非常好的起点！\n",
    "# \n",
    "# 您可以在我们的“数据整理”课程中详细学习如何处理更复杂的数据。\n",
    "# \n",
    "# 如果您正在做我们的 OpenStreetMaps 项目，可按照此处介绍的方法导入 CSV。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bounds']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f8d53c76982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m#     test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mcount_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'example.osm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Done!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0f8d53c76982>\u001b[0m in \u001b[0;36mcount_tags\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# 练习: 迭代解析\n",
    "# 你的任务是使用迭代解析处理地图文件，并找出有什么样的标记，以及有多少个，\n",
    "# 以便了解预计在地图中的每个类别有多少数据。请填写count_tags 函数。\n",
    "# 它应该返回一个字典，标记名（tag name）是键，该标记在地图中出现的次数是值。\n",
    "# \n",
    "# 注意，你需要使用“example.osm”之外的数据文件测试代码\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "chicago_osm = 'C:/Users/lk235/Desktop/DATA/chicago_illinois.osm/chicago_illinois.osm'\n",
    "\n",
    "wenzhou_osm = 'C:/Users/lk235/Desktop/DATA/wenzhou.osm'\n",
    "       \n",
    "def count_tags(filename):\n",
    "    osm_file = open(filename, \"r\")\n",
    "    tags = {}\n",
    "    pattern = re.compile(\"'(.*)'\")\n",
    "    for event, elem in ET.iterparse(osm_file):\n",
    "        k = str(pattern.findall(str(elem))).strip('[]').strip('\\'')\n",
    "        # k = pattern.findall(str(elem))\n",
    "        print k\n",
    "        if k not in tags.keys():\n",
    "            tags[k] = 1\n",
    "        else:\n",
    "            tags[k] = tags[k] + 1\n",
    "        \n",
    "    return tags\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    tags = count_tags('example.osm')\n",
    "    pprint.pprint(tags)\n",
    "    assert tags == {'bounds': 1,\n",
    "                     'member': 3,\n",
    "                     'nd': 4,\n",
    "                     'node': 20,\n",
    "                     'osm': 1,\n",
    "                     'relation': 1,\n",
    "                     'tag': 7,\n",
    "                     'way': 1}\n",
    "\n",
    "    \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test()\n",
    "\n",
    "print count_tags('example.osm')\n",
    "print 'Done!'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problemchars': 0, 'lower': 7, 'other': 0, 'lower_colon': 0}\n"
     ]
    }
   ],
   "source": [
    "# 练习: 标签类型\n",
    "# 题目说明\n",
    "# 你的任务是进一步探索数据。\n",
    "# \n",
    "# 在处理数据并将其添加到数据库中之前，你应该检查每个“<标记>”的“k”值，看看是否存在潜在问题。\n",
    "# \n",
    "# 我们提供了 3 个正则表达式，用来检查标记的某些规律。正如在上一道测验中看到的，我们想要更改数据模型，\n",
    "# 并将“addr:street”类型的键展开为字典，如下所示：\n",
    "# {\"address\": {\"street\": \"Some value\"}}\n",
    "# \n",
    "# 我们需要查看是否有此类标记，以及任何标记是否存在具有问题的字符。\n",
    "# \n",
    "# 请完成函数“key_type”，并得出这四大标记类别在字典中的各自数量：\n",
    "# \n",
    "# “lower”，表示仅包含小写字母且有效的标记，\n",
    "# “lower_colon”，表示名称中有冒号的其他有效标记，\n",
    "# “problemchars”，表示字符存在问题的标记，以及\n",
    "# “other”，表示不属于上述三大类别的其他标记。\n",
    "# 请参阅“process_map”和“test”函数，了解我们期望的格式。\n",
    "# 如果你对使用正则表达式的 re 模块需要帮助，可以参考这个文档，尤其是 7.2.3 和 7.2.5.3。\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        k = element.attrib['k']\n",
    "        # print element.attrib['k'],element.attrib['v']\n",
    "        if  lower_colon.search(k):\n",
    "            keys['lower_colon'] = keys['lower_colon'] + 1\n",
    "            \n",
    "            \n",
    "        elif  lower.search(k):\n",
    "            keys['lower'] = keys['lower'] + 1\n",
    "        elif  problemchars.search(k):\n",
    "            keys['problemchars'] = keys['problemchars'] + 1\n",
    "        else:\n",
    "            keys['other'] = keys['other'] + 1\n",
    "        pass\n",
    "        \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def test():\n",
    "    # You can use another testfile 'map.osm' to look at your solution\n",
    "    # Note that the assertion below will be incorrect then.\n",
    "    # Note as well that the test function here is only used in the Test Run;\n",
    "    # when you submit, your code will be checked against a different dataset.\n",
    "    keys = process_map('example.osm')\n",
    "    pprint.pprint(keys)\n",
    "    assert keys == {'lower': 5, 'lower_colon': 0, 'other': 1, 'problemchars': 1}\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test()\n",
    "\n",
    "print process_map('example.osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1219059', '147510', '26299', '451048', '567034', '939355'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 练习: 探索用户\n",
    "# 题目说明\n",
    "# 你的任务是进一步探索数据。\n",
    "# \n",
    "# 第一项任务比较有趣，查找这一特定地区有多少唯一用户向地图做出了贡献！\n",
    "# \n",
    "# 函数 process_map 应该返回一组唯一的用户 ID（“uid”）\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "def get_user(element):\n",
    "    \n",
    "    return \n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if 'uid' in  element.attrib:\n",
    "            users.add(element.attrib['uid'])\n",
    "       \n",
    "\n",
    "        pass\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    users = process_map('example.osm')\n",
    "    pprint.pprint(users)\n",
    "    assert len(users) == 6\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test()\n",
    "\n",
    "process_map('example.osm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习: 完善街道名\n",
    "# 题目说明\n",
    "# 在这道练习中，你需要完成以下两步：\n",
    "# \n",
    "# 审核 OSMFILE 并更改变量“mapping”，表示为了修正预期列表中相应项的错误街道类型需要做出的更改。 \n",
    "# 你必须仅为在此 OSMFILE 中发现的实际问题添加映射，而不是泛化的解决方案，因为这将取决于你要审核的特定区域。\n",
    "# 编写 update_name 函数，实际地修正街道名称。该函数传入街道名称作为参数，应该返回修正过后的名称。\n",
    "# 我们提供了一个简单的测试，使你能够了解我们的预期结果。\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"example.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            'Rd.':'Road',\n",
    "            'Ave':\"Avenue\"\n",
    "            \n",
    "            }\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        print street_type\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            \n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    \n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "              \n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    m = street_type_re.search(name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        replace = mapping[street_type]\n",
    "       \n",
    "        name = name.replace(street_type,replace)\n",
    "        \n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def test():\n",
    "    st_types = audit(OSMFILE)\n",
    "    assert len(st_types) == 3\n",
    "    pprint.pprint(dict(st_types))\n",
    "\n",
    "    for st_type, ways in st_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print name, \"=>\", better_name\n",
    "            if name == \"West Lexington St.\":\n",
    "                assert better_name == \"West Lexington Street\"\n",
    "            if name == \"Baldwin Rd.\":\n",
    "                assert better_name == \"Baldwin Road\"\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     test()\n",
    "# st_types = audit('example1.osm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习: 为数据集做准备 - SQL\n",
    "# 题目说明\n",
    "# 完成审核后，下一步是准备要插入 SQL 数据库中的数据。为此，你将解析OSM XML 文件中的元素，\n",
    "# 将这些元素从文档形式转换为表格形式，从而能够写入 .csv 文件。\n",
    "# 然后，这些 csv 文件就可以作为表格轻松地导入 SQL 数据库中。\n",
    "# \n",
    "# 该转换的流程如下所示：\n",
    "# \n",
    "# 使用 iterparse 迭代遍历 XML 中的每个顶级元素\n",
    "# 使用自定义函数将每个元素变成多个数据结构\n",
    "# 利用架构和验证库确保转换的数据格式正确\n",
    "# 将每个数据结构写入相应的 .csv 文件\n",
    "# 我们已经提供加载数据、进行迭代解析和将输出写入 csv 文件所需的代码。\n",
    "# 你的任务是完成 shape_element 函数，该函数会将每个元素转换为正确的格式。\n",
    "# 为了便于你完成这一流程，\n",
    "# 我们已经为 .csv 文件和最终表格定义了架构（请参阅最后一个代码标签中的 schema.py 文件）。\n",
    "# 我们可以使用 Cerberus 库对照该架构验证输出是否正确。\n",
    "# \n",
    "# 确定元素函数的结构\n",
    "# \n",
    "# 该函数应该将 iterparse Element 对象作为输入，并返回字典。\n",
    "# \n",
    "# 如果元素顶级标记是“node”：\n",
    "# \n",
    "# 返回的字典格式应该为 {\"node\": .., \"node_tags\": ...}\n",
    "# \n",
    "# “node”字段应该存储以下顶级节点属性的字典：\n",
    "# \n",
    "# id\n",
    "# user\n",
    "# uid\n",
    "# version\n",
    "# lat\n",
    "# lon\n",
    "# timestamp\n",
    "# changeset\n",
    "# 所有其他属性都可以忽略\n",
    "# \n",
    "# “node_tags”字段应该存储字典列表，每个次级标记一个字典。次级标记是标记名称/类型为“tag”的节点的子标记。\n",
    "# 每个字典应该包含次级标记属性中的以下字段：\n",
    "# \n",
    "# id：顶级节点 ID 属性值\n",
    "# key：如果没有冒号，则是完整的标记“k”属性值，如果有冒号，则是冒号后面的字符。\n",
    "# value：标记“v”属性值\n",
    "# type：标记“k”值中冒号前面的字符，或者如果没有冒号的话，则是“regular”。\n",
    "# 此外，\n",
    "# \n",
    "# 如果标记“k”值包含存在问题的字符，则应该忽略该标记\n",
    "# 如果标记“k”值包含“:”，则“:”前面的字符应该设为标记类型，“:” 后面的字符应该设为标记键\n",
    "# 如果“k”值中包含其他“:”，则应该忽略这些“:”并保留为标记键的一部分。例如：\n",
    "# <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "# 应该变成\n",
    "# {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "# 如果节点没有次级标记，那么“node_tags”字段应该包含空列表。\n",
    "# \n",
    "# “node”元素的最终返回值应该如下所示：\n",
    "# {'node': {'id': 757860928,\n",
    "#           'user': 'uboot',\n",
    "#           'uid': 26299,\n",
    "#        'version': '2',\n",
    "#           'lat': 41.9747374,\n",
    "#           'lon': -87.6920102,\n",
    "#           'timestamp': '2010-07-22T16:16:51Z',\n",
    "#       'changeset': 5288876},\n",
    "#  'node_tags': [{'id': 757860928,\n",
    "#                 'key': 'amenity',\n",
    "#                 'value': 'fast_food',\n",
    "#                 'type': 'regular'},\n",
    "#                {'id': 757860928,\n",
    "#                 'key': 'cuisine',\n",
    "#                 'value': 'sausage',\n",
    "#                 'type': 'regular'},\n",
    "#                {'id': 757860928,\n",
    "#                 'key': 'name',\n",
    "#                 'value': \"Shelly's Tasty Freeze\",\n",
    "#                 'type': 'regular'}]}\n",
    "# 如果元素的顶级标记是 “way”：\n",
    "# \n",
    "# 则字典的格式应该是 {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "# \n",
    "# “way” 字段应该存储以下顶级 way 属性的字典：\n",
    "# \n",
    "# id\n",
    "# user\n",
    "# uid\n",
    "# version\n",
    "# timestamp\n",
    "# changeset\n",
    "# 所有其他属性均可以忽略\n",
    "# \n",
    "# “way_tags”字段应该存储字典列表，并遵守和“node_tags”完全一样的规则。\n",
    "# \n",
    "# 此外，字典应该具有字段“way_nodes”。“way_nodes”应该存储字典列表，每个节点子标记对应一个字典。每个字典应该具有以下字段：\n",
    "# \n",
    "# id：顶级元素 (way) ID\n",
    "# node_id：节点标记的 ref 属性值\n",
    "# position： 节点标记的索引（从 0 开始），即节点标记在 way 元素中出现的顺序\n",
    "# “way”元素的最终返回值应该如下所示：\n",
    "# {'way': {'id': 209809850,\n",
    "#          'user': 'chicago-buildings',\n",
    "#          'uid': 674454,\n",
    "#          'version': '1',\n",
    "#          'timestamp': '2013-03-13T15:58:04Z',\n",
    "#          'changeset': 15353317},\n",
    "#  'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "#                {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "#                {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "#                {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "#                {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "#                {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "#                {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    "#  'way_tags': [{'id': 209809850,\n",
    "#                'key': 'housenumber',\n",
    "#                'type': 'addr',\n",
    "#                'value': '1412'},\n",
    "#               {'id': 209809850,\n",
    "#                'key': 'street',\n",
    "#                'type': 'addr',\n",
    "#                'value': 'West Lexington St.'},\n",
    "#               {'id': 209809850,\n",
    "#                'key': 'street:name',\n",
    "#                'type': 'addr',\n",
    "#                'value': 'Lexington'},\n",
    "#               {'id': '209809850',\n",
    "#                'key': 'street:prefix',\n",
    "#                'type': 'addr',\n",
    "#                'value': 'West'},\n",
    "#               {'id': 209809850,\n",
    "#                'key': 'street:type',\n",
    "#                'type': 'addr',\n",
    "#                'value': 'Street'},\n",
    "#               {'id': 209809850,\n",
    "#                'key': 'building',\n",
    "#                'type': 'regular',\n",
    "#                'value': 'yes'},\n",
    "#               {'id': 209809850,\n",
    "#                'key': 'levels',\n",
    "#                'type': 'building',\n",
    "#                'value': '1'},\n",
    "#               {'id': 209809850,\n",
    "#                'key': 'building_id',\n",
    "#                'type': 'chicago',\n",
    "#                'value': '366409'}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node': {'changeset': '11129782', 'uid': '451048', 'timestamp': '2012-03-28T18:31:23Z', 'lon': '-87.6866303', 'version': '7', 'user': 'bbmiller', 'lat': '41.9730791', 'id': '261114295'}, 'node_tags': []}\n{'node': {'changeset': '8448766', 'uid': '451048', 'timestamp': '2011-06-15T17:04:54Z', 'lon': '-87.6878512', 'version': '6', 'user': 'bbmiller', 'lat': '41.9730416', 'id': '261114296'}, 'node_tags': []}\n{'node': {'changeset': '8581395', 'uid': '451048', 'timestamp': '2011-06-29T14:14:14Z', 'lon': '-87.6939548', 'version': '5', 'user': 'bbmiller', 'lat': '41.9729565', 'id': '261114299'}, 'node_tags': []}\n{'node': {'changeset': '8581395', 'uid': '451048', 'timestamp': '2011-06-29T14:14:14Z', 'lon': '-87.6976025', 'version': '5', 'user': 'bbmiller', 'lat': '41.9707380', 'id': '261146436'}, 'node_tags': []}\n{'node': {'changeset': '8581395', 'uid': '451048', 'timestamp': '2011-06-29T14:14:15Z', 'lon': '-87.6988576', 'version': '7', 'user': 'bbmiller', 'lat': '41.9740068', 'id': '261147304'}, 'node_tags': []}\n{'node': {'changeset': '8581395', 'uid': '451048', 'timestamp': '2011-06-29T14:14:14Z', 'lon': '-87.6938669', 'version': '5', 'user': 'bbmiller', 'lat': '41.9707656', 'id': '261224274'}, 'node_tags': []}\n{'node': {'changeset': '8448766', 'uid': '451048', 'timestamp': '2011-06-15T16:55:37Z', 'lon': '-87.6890403', 'version': '47', 'user': 'bbmiller', 'lat': '41.9730154', 'id': '293816175'}, 'node_tags': []}\n{'node': {'changeset': '15348240', 'uid': '567034', 'timestamp': '2013-03-13T07:46:29Z', 'lon': '-87.6891198', 'version': '37', 'user': 'Umbugbene', 'lat': '41.9749225', 'id': '305896090'}, 'node_tags': []}\n{'node': {'changeset': '15348240', 'uid': '567034', 'timestamp': '2013-03-13T08:02:56Z', 'lon': '-87.7012430', 'version': '12', 'user': 'Umbugbene', 'lat': '41.9740292', 'id': '317636974'}, 'node_tags': []}\n{'node': {'changeset': '15348240', 'uid': '567034', 'timestamp': '2013-03-13T08:08:01Z', 'lon': '-87.6979712', 'version': '13', 'user': 'Umbugbene', 'lat': '41.9740556', 'id': '317636971'}, 'node_tags': []}\n{'node': {'changeset': '14927972', 'uid': '567034', 'timestamp': '2013-02-05T22:43:49Z', 'lon': '-87.7012048', 'version': '2', 'user': 'Umbugbene', 'lat': '41.9705609', 'id': '317637399'}, 'node_tags': []}\n{'node': {'changeset': '14927972', 'uid': '567034', 'timestamp': '2013-02-05T22:43:49Z', 'lon': '-87.7012109', 'version': '2', 'user': 'Umbugbene', 'lat': '41.9706972', 'id': '317637398'}, 'node_tags': []}\n{'node': {'changeset': '8448766', 'uid': '451048', 'timestamp': '2011-06-15T17:04:54Z', 'lon': '-87.6847998', 'version': '3', 'user': 'bbmiller', 'lat': '41.9731130', 'id': '365214872'}, 'node_tags': []}\n{'node': {'changeset': '8581395', 'uid': '451048', 'timestamp': '2011-06-29T14:14:15Z', 'lon': '-87.6988886', 'version': '6', 'user': 'bbmiller', 'lat': '41.9747482', 'id': '261299091'}, 'node_tags': []}\n{'node': {'changeset': '8448766', 'uid': '451048', 'timestamp': '2011-06-15T17:04:54Z', 'lon': '-87.6841979', 'version': '6', 'user': 'bbmiller', 'lat': '41.9731219', 'id': '261114294'}, 'node_tags': []}\n{'node': {'changeset': '3359748', 'uid': '147510', 'timestamp': '2009-12-13T00:36:09Z', 'lon': '-87.7000019', 'version': '4', 'user': 'woodpeck_fixbot', 'lat': '41.9707217', 'id': '261210804'}, 'node_tags': []}\n{'node': {'changeset': '8581395', 'uid': '451048', 'timestamp': '2011-06-29T14:14:15Z', 'lon': '-87.6922652', 'version': '7', 'user': 'bbmiller', 'lat': '41.9748542', 'id': '261221422'}, 'node_tags': []}\n{'node': {'changeset': '8581395', 'uid': '451048', 'timestamp': '2011-06-29T14:14:15Z', 'lon': '-87.6923639', 'version': '7', 'user': 'bbmiller', 'lat': '41.9758794', 'id': '261221424'}, 'node_tags': [{'value': 'traffic_signals', 'type': 'regular', 'id': '261221424', 'key': 'highway'}]}\n{'node': {'changeset': '17206049', 'uid': '1219059', 'timestamp': '2013-08-03T16:43:42Z', 'lon': '-87.6921867', 'version': '2', 'user': 'linuxUser16', 'lat': '41.9757030', 'id': '2406124091'}, 'node_tags': [{'value': 'Chicago', 'type': 'addr', 'id': '2406124091', 'key': 'city'}, {'value': '5157', 'type': 'addr', 'id': '2406124091', 'key': 'housenumber'}, {'value': '60625', 'type': 'addr', 'id': '2406124091', 'key': 'postcode'}, {'value': 'North Lincoln Ave', 'type': 'addr', 'id': '2406124091', 'key': 'street'}, {'value': 'restaurant', 'type': 'regular', 'id': '2406124091', 'key': 'amenity'}, {'value': 'mexican', 'type': 'regular', 'id': '2406124091', 'key': 'cuisine'}, {'value': 'La Cabana De Don Luis', 'type': 'regular', 'id': '2406124091', 'key': 'name'}, {'value': 'no', 'type': 'regular', 'id': '2406124091', 'key': 'outdoor_seating'}, {'value': '1 (773)-271-5176', 'type': 'regular', 'id': '2406124091', 'key': 'phone'}, {'value': 'no', 'type': 'regular', 'id': '2406124091', 'key': 'smoking'}, {'value': 'yes', 'type': 'regular', 'id': '2406124091', 'key': 'takeaway'}]}\n{'node': {'changeset': '20187349', 'uid': '1219059', 'timestamp': '2014-01-25T01:56:10Z', 'lon': '-87.6900344', 'version': '1', 'user': 'linuxUser16', 'lat': '41.9705219', 'id': '2636084635'}, 'node_tags': [{'value': 'Chicago', 'type': 'addr', 'id': '2636084635', 'key': 'city'}, {'value': 'US', 'type': 'addr', 'id': '2636084635', 'key': 'country'}, {'value': '4874', 'type': 'addr', 'id': '2636084635', 'key': 'housenumber'}, {'value': '60625', 'type': 'addr', 'id': '2636084635', 'key': 'postcode'}, {'value': 'Illinois', 'type': 'addr', 'id': '2636084635', 'key': 'state'}, {'value': 'N. Lincoln Ave', 'type': 'addr', 'id': '2636084635', 'key': 'street'}, {'value': 'Matty Ks', 'type': 'regular', 'id': '2636084635', 'key': 'name'}, {'value': '(773)-654-1347', 'type': 'regular', 'id': '2636084635', 'key': 'phone'}, {'value': 'doityourself', 'type': 'regular', 'id': '2636084635', 'key': 'shop'}, {'value': 'GPS', 'type': 'regular', 'id': '2636084635', 'key': 'source'}]}\n{'node': {'changeset': '8581395', 'uid': '451048', 'timestamp': '2011-06-29T14:14:13Z', 'lon': '-87.6963097', 'version': '6', 'user': 'bbmiller', 'lat': '41.9707413', 'id': '261198953'}, 'node_tags': []}\n{'node': {'changeset': '5288876', 'uid': '26299', 'timestamp': '2010-07-22T16:16:51Z', 'lon': '-87.6920102', 'version': '2', 'user': 'uboot', 'lat': '41.9747374', 'id': '757860928'}, 'node_tags': [{'value': 'fast_food', 'type': 'regular', 'id': '757860928', 'key': 'amenity'}, {'value': 'sausage', 'type': 'regular', 'id': '757860928', 'key': 'cuisine'}, {'value': \"Shelly's Tasty Freeze\", 'type': 'regular', 'id': '757860928', 'key': 'name'}]}\n{'way_tags': [{'value': 'service', 'type': 'regular', 'id': '258219703', 'key': 'highway'}], 'way_nodes': [{'position': 0, 'node_id': '2636086179', 'id': '258219703'}, {'position': 1, 'node_id': '2636086178', 'id': '258219703'}, {'position': 2, 'node_id': '2636086177', 'id': '258219703'}, {'position': 3, 'node_id': '2636086176', 'id': '258219703'}], 'way': {'changeset': '20187382', 'uid': '1219059', 'timestamp': '2014-01-25T02:01:54Z', 'version': '1', 'user': 'linuxUser16', 'id': '258219703'}}\n{'node': {'changeset': '11043902', 'uid': '634589', 'timestamp': '2012-03-20T18:56:44Z', 'lon': '-88.0780576', 'version': '2', 'user': 'Jacobs Studios', 'lat': '42.1251718', 'id': '1683602133'}, 'node_tags': [{'value': 'Village Hall', 'type': 'addr', 'id': '1683602133', 'key': 'housename'}, {'value': '1400', 'type': 'addr', 'id': '1683602133', 'key': 'housenumber'}, {'value': '60067', 'type': 'addr', 'id': '1683602133', 'key': 'postcode'}, {'value': 'Baldwin Rd.', 'type': 'addr', 'id': '1683602133', 'key': 'street'}, {'value': 'townhall', 'type': 'regular', 'id': '1683602133', 'key': 'amenity'}, {'value': 'Village Hall', 'type': 'regular', 'id': '1683602133', 'key': 'name'}]}\n{'way_tags': [{'value': '1412', 'type': 'addr', 'id': '209809850', 'key': 'housenumber'}, {'value': 'West Lexington St.', 'type': 'addr', 'id': '209809850', 'key': 'street'}, {'value': 'Lexington', 'type': 'addr', 'id': '209809850', 'key': 'street:name'}, {'value': 'West', 'type': 'addr', 'id': '209809850', 'key': 'street:prefix'}, {'value': 'Street', 'type': 'addr', 'id': '209809850', 'key': 'street:type'}, {'value': 'yes', 'type': 'regular', 'id': '209809850', 'key': 'building'}, {'value': '1', 'type': 'building', 'id': '209809850', 'key': 'levels'}, {'value': '366409', 'type': 'chicago', 'id': '209809850', 'key': 'building_id'}], 'way_nodes': [{'position': 0, 'node_id': '2199822281', 'id': '209809850'}, {'position': 1, 'node_id': '2199822390', 'id': '209809850'}, {'position': 2, 'node_id': '2199822392', 'id': '209809850'}, {'position': 3, 'node_id': '2199822369', 'id': '209809850'}, {'position': 4, 'node_id': '2199822370', 'id': '209809850'}, {'position': 5, 'node_id': '2199822284', 'id': '209809850'}, {'position': 6, 'node_id': '2199822281', 'id': '209809850'}], 'way': {'changeset': '15353317', 'uid': '674454', 'timestamp': '2013-03-13T15:58:04Z', 'version': '1', 'user': 'chicago-buildings', 'id': '209809850'}}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import cerberus\n",
    "\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"example1.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "    \n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    el_id = element.attrib['id']\n",
    "    \n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        node_attribs = element.attrib\n",
    "        for k in node_attribs.keys():\n",
    "            if k not in node_attr_fields:\n",
    "                del node_attribs[k]\n",
    "        \n",
    "        \n",
    "        for tag in element.iter(\"tag\"):\n",
    "            tag_dict = {}\n",
    "            key = tag.attrib['k']\n",
    "            if not problem_chars.search(key):\n",
    "                \n",
    "                if LOWER_COLON.search(key):\n",
    "                    tag_dict['type'] = key.split(':')[0]\n",
    "                    tag_dict['key'] = key.split(':',1)[1]\n",
    "                else:\n",
    "                    tag_dict['type'] = default_tag_type\n",
    "                    tag_dict['key'] = key\n",
    "               \n",
    "                tag_dict['id'] = el_id   \n",
    "                tag_dict['value'] = tag.attrib['v']\n",
    "                tags.append(tag_dict)\n",
    "        print {'node': node_attribs, 'node_tags': tags}\n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        way_attribs = element.attrib\n",
    "        for k in way_attribs.keys():\n",
    "            if k not in way_attr_fields:\n",
    "                del way_attribs[k]\n",
    "       \n",
    "        position = 0\n",
    "        for tag in element.iter():\n",
    "            way_dict = {}\n",
    "            \n",
    "            tag_dict = {}\n",
    "            if tag.tag == 'tag':\n",
    "                 key = tag.attrib['k']\n",
    "                 tag_dict['id'] = el_id \n",
    "                 if not problem_chars.search(key):\n",
    "                     if LOWER_COLON.search(key):\n",
    "                         tag_dict['type'] = key.split(':')[0]\n",
    "                         tag_dict['key'] = key.split(':',1)[1]\n",
    "                     else:\n",
    "                         tag_dict['type'] = default_tag_type\n",
    "                         tag_dict['key'] = key\n",
    "\n",
    "                 tag_dict['value'] = tag.attrib['v']\n",
    "                 tags.append(tag_dict)\n",
    "                \n",
    "            if tag.tag == 'nd':\n",
    "                way_dict['id'] = el_id\n",
    "                way_dict['node_id'] = tag.attrib['ref']\n",
    "                way_dict['position'] = position\n",
    "                position = position + 1\n",
    "                way_nodes.append(way_dict)\n",
    "        print  {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}  \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    \n",
    "    \n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "#     # sample of the map when validating.\n",
    "\n",
    "    # process_map(OSM_PATH, validate=True)\n",
    "                \n",
    "elements = get_element('example1.osm')\n",
    "for element in elements:\n",
    "    shape_element(element)\n",
    "    \n",
    "# str = '123:235:456'\n",
    "# print str.split(':',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
