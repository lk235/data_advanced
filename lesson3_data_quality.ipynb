{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#数据质量\n",
    "# 一 有效性：审核有效性是关于确定对个别字段施加什么约束并检查以确保字段值遵守这些约束条件\n",
    "# 跨字段限制：当一个数据项拥有多个字段时，它们必须在某种程度上具有一致性\n",
    "#准确率\n",
    "#完整性\n",
    "#一致性\n",
    "#统一性\n",
    "\n",
    "#使用蓝图的示例\n",
    "#!/usr/bin/env python\n",
    "          # -*- coding: utf-8 -*-\n",
    "          import xml.etree.cElementTree as ET\n",
    "          from collections import defaultdict\n",
    "          import re\n",
    "\n",
    "          osm_file = open(\"chicago.osm\", \"r\")\n",
    "\n",
    "          street_type_re = re.compile(r'\\S+\\.?$', re.IGNORECASE)\n",
    "          street_types = defaultdict(int)\n",
    "\n",
    "          def audit_street_type(street_types, street_name):\n",
    "              m = street_type_re.search(street_name)\n",
    "              if m:\n",
    "                  street_type = m.group()\n",
    "\n",
    "                  street_types[street_type] += 1\n",
    "\n",
    "          def print_sorted_dict(d):\n",
    "              keys = d.keys()\n",
    "              keys = sorted(keys, key=lambda s: s.lower())\n",
    "              for k in keys:\n",
    "                  v = d[k]\n",
    "                  print \"%s: %d\" % (k, v) \n",
    "\n",
    "          def is_street_name(elem):\n",
    "              return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "          def audit():\n",
    "              for event, elem in ET.iterparse(osm_file):\n",
    "                  if is_street_name(elem):\n",
    "                      audit_street_type(street_types, elem.attrib['v'])    \n",
    "              print_sorted_dict(street_types)    \n",
    "\n",
    "          if __name__ == '__main__':\n",
    "              audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#练习: 修正有效性\n",
    "# Your task is to check the \"productionStartYear\" of the DBPedia autos datafile for valid values.\n",
    "# The following things should be done:\n",
    "# - check if the field \"productionStartYear\" contains a year\n",
    "# - check if the year is in range 1886-2014\n",
    "# - convert the value of the field to be just a year (not full datetime)\n",
    "# - the rest of the fields and values should stay the same\n",
    "# - if the value of the field is a valid year in the range as described above,\n",
    "#   write that line to the output_good file\n",
    "# - if the value of the field is not a valid year as described above, \n",
    "#   write that line to the output_bad file\n",
    "# - discard rows (neither write to good nor bad) if the URI is not from dbpedia.org\n",
    "# - you should use the provided way of reading and writing data (DictReader and DictWriter)\n",
    "#   They will take care of dealing with the header.\n",
    "# 你的任务是检查 DBPedia 自动数据文件的“productionStartYear”并获取有效的值。应该完成以下任务：\n",
    "# -    检查字段“productionStartYear”是否包含年份\n",
    "# -    检查该年份是否在 1886 至 2014 范围内\n",
    "# -    将字段值转换为年份（而不是整个日期时间）\n",
    "# -    字段的其他部分和值应该保持不变\n",
    "# -    如果字段的值是如上所述范围内的有效年份，则将该行写入 output_good 文件中\n",
    "# -    如果字段的值不是如上所述的有效年份，则将该行写入 output_bad 文件中\n",
    "# -    你应该采用提供的数据读取和写入方式（DictReader 和 DictWriter），它们将会对标题进行处理。\n",
    "# \n",
    "# You can write helper functions for checking the data and writing the files, but we will call only the \n",
    "# 'process_file' with 3 arguments (inputfile, output_good, output_bad).\n",
    "# 你可以编写辅助函数来检查数据并编写文件，\n",
    "# 但是我们将仅调用包含三个参数（inputfile、output_good、output_bad）的“process_file”文件。\n",
    "\n",
    "import csv\n",
    "import pprint\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "INPUT_FILE = 'autos.csv'\n",
    "OUTPUT_GOOD = 'autos-valid.csv'\n",
    "OUTPUT_BAD = 'FIXME-autos.csv'\n",
    "good = []\n",
    "bad = []\n",
    "\n",
    "def process_file(input_file, output_good, output_bad):\n",
    "\n",
    "    # with open(input_file, \"r\") as f:\n",
    "    #     reader = csv.DictReader(f)\n",
    "    #     header = reader.fieldnames\n",
    "    #     print header\n",
    "    \n",
    "    with open(input_file, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        # good.append(header)\n",
    "        # bad.append(header)\n",
    "        p = re.compile('\\d{4}', re.IGNORECASE)\n",
    "        for row in reader:\n",
    "            if row['URI'].find(\"dbpedia.org\") < 0:\n",
    "                continue\n",
    "            m =re.search('\\d{4}',row['productionStartYear'])\n",
    "            if m:\n",
    "                year = int(m.group())\n",
    "                if year > 1886 and year <  2014:\n",
    "                     row['productionStartYear'] = year\n",
    "                     good.append(row)\n",
    "                else:\n",
    "                    row['productionStartYear'] = year\n",
    "                    bad.append(row)\n",
    "                    \n",
    "            else:\n",
    "                bad.append(row)\n",
    "        \n",
    "\n",
    "        #COMPLETE THIS FUNCTION\n",
    "\n",
    "\n",
    "\n",
    "    # This is just an example on how you can use csv.DictWriter\n",
    "    # Remember that you have to output 2 files\n",
    "    \n",
    "    with open(output_good, \"w\") as g:\n",
    "        writer = csv.DictWriter(g, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in good:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "            \n",
    "    with open(output_bad, \"w\") as g:\n",
    "        writer = csv.DictWriter(g, delimiter=\",\", fieldnames= header)\n",
    "        writer.writeheader()\n",
    "        for row in bad:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    process_file(INPUT_FILE, OUTPUT_GOOD, OUTPUT_BAD)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "        # print datetime.strptime(row['productionStartYear'],\"%Y%d%m\")\n",
    "        \n",
    "        \n",
    "    \n",
    "test()\n",
    "\n",
    "# ANSWER:\n",
    "# def process_file(input_file, output_good, output_bad):\n",
    "#     # store data into lists for output\n",
    "#     data_good = []\n",
    "#     data_bad = []\n",
    "#     with open(input_file, \"r\") as f:\n",
    "#         reader = csv.DictReader(f)\n",
    "#         header = reader.fieldnames\n",
    "#         for row in reader:\n",
    "#             # validate URI value\n",
    "#             if row['URI'].find(\"dbpedia.org\") < 0:\n",
    "#                 continue\n",
    "# \n",
    "#             ps_year = row['productionStartYear'][:4]\n",
    "#             try: # use try/except to filter valid items\n",
    "#                 ps_year = int(ps_year)\n",
    "#                 row['productionStartYear'] = ps_year\n",
    "#                 if (ps_year >= 1886) and (ps_year <= 2014):\n",
    "#                     data_good.append(row)\n",
    "#                 else:\n",
    "#                     data_bad.append(row)\n",
    "#             except ValueError: # non-numeric strings caught by exception\n",
    "#                 if ps_year == 'NULL':\n",
    "#                     data_bad.append(row)\n",
    "# \n",
    "#     # Write processed data to output files\n",
    "#     with open(output_good, \"w\") as good:\n",
    "#         writer = csv.DictWriter(good, delimiter=\",\", fieldnames= header)\n",
    "#         writer.writeheader()\n",
    "#         for row in data_good:\n",
    "#             writer.writerow(row)\n",
    "# \n",
    "#     with open(output_bad, \"w\") as bad:\n",
    "#         writer = csv.DictWriter(bad, delimiter=\",\", fieldnames= header)\n",
    "#         writer.writeheader()\n",
    "#         for row in data_bad:\n",
    "#             writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['URI', 'rdf-schema#label', 'rdf-schema#comment', 'administrativeDistrict_label', 'administrativeDistrict', 'anthem_label', 'anthem', 'area', 'areaCode', 'areaLand', 'areaMetro', 'areaRural', 'areaTotal', 'areaUrban', 'areaWater', 'city_label', 'city', 'code', 'country_label', 'country', 'daylightSavingTimeZone_label', 'daylightSavingTimeZone', 'district_label', 'district', 'division_label', 'division', 'elevation', 'federalState_label', 'federalState', 'foundingDate', 'foundingPerson_label', 'foundingPerson', 'foundingYear', 'governingBody_label', 'governingBody', 'government_label', 'government', 'governmentType_label', 'governmentType', 'isPartOf_label', 'isPartOf', 'isoCodeRegion_label', 'isoCodeRegion', 'leader_label', 'leader', 'leaderName_label', 'leaderName', 'leaderParty_label', 'leaderParty', 'leaderTitle', 'location_label', 'location', 'maximumElevation', 'mayor_label', 'mayor', 'minimumElevation', 'motto', 'municipality_label', 'municipality', 'part_label', 'part', 'percentageOfAreaWater', 'populationAsOf', 'populationDensity', 'populationMetro', 'populationMetroDensity', 'populationRural', 'populationTotal', 'populationTotalRanking', 'populationUrban', 'populationUrbanDensity', 'postalCode', 'region_label', 'region', 'state_label', 'state', 'synonym', 'thumbnail_label', 'thumbnail', 'timeZone_label', 'timeZone', 'twinCity_label', 'twinCity', 'twinCountry_label', 'twinCountry', 'type_label', 'type', 'utcOffset', 'point', '22-rdf-syntax-ns#type_label', '22-rdf-syntax-ns#type', 'wgs84_pos#lat', 'wgs84_pos#long', 'depiction_label', 'depiction', 'homepage_label', 'homepage', 'name', 'nick']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'areaCode': {float, list, NoneType, str},\n 'areaLand': {float, list, NoneType},\n 'areaMetro': {float, list, NoneType},\n 'areaUrban': {float, list, NoneType},\n 'elevation': {float, list, NoneType},\n 'governmentType_label': {list, NoneType, str},\n 'homepage': {list, NoneType, str},\n 'isPartOf_label': {list, NoneType, str},\n 'maximumElevation': {float, list, NoneType},\n 'minimumElevation': {float, NoneType},\n 'name': {list, NoneType, str},\n 'populationDensity': {float, list, NoneType},\n 'populationTotal': {float, list, NoneType},\n 'timeZone_label': {list, NoneType, str},\n 'utcOffset': {float, int, list, NoneType, str},\n 'wgs84_pos#lat': {float, list, NoneType},\n 'wgs84_pos#long': {float, list, NoneType}}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#练习: 审查数据质量\n",
    "# In this problem set you work with cities infobox data, audit it, come up with a\n",
    "# cleaning idea and then clean it up. In the first exercise we want you to audit\n",
    "# the datatypes that can be found in some particular fields in the dataset.\n",
    "# The possible types of values can be:\n",
    "# - NoneType if the value is a string \"NULL\" or an empty string \"\"\n",
    "# - list, if the value starts with \"{\"\n",
    "# - int, if the value can be cast to int\n",
    "# - float, if the value can be cast to float, but CANNOT be cast to int.\n",
    "#    For example, '3.23e+07' should be considered a float because it can be cast\n",
    "#    as float but int('3.23e+07') will throw a ValueError\n",
    "# - 'str', for all other values\n",
    "# 在此习题集中，你将处理城市 infobox 数据，对数据进行审核，然后想出清理方法并清理数据。在第一道练习中，请审核\n",
    "# 数据集中某些特定字段中的数据类型。\n",
    "# 值类型可以是：\n",
    "# -    NoneType，如果值是字符串“NULL”或空字符串“”\n",
    "# -    列表，如果值以“{”开头\n",
    "# -    整型，如果值可以转型为整型\n",
    "# -    浮点型，如果值可以转型为浮点型，但是无法转型为整型。\n",
    "# 例如，“3.23e+07”应该被当做浮点型，因为可以转型为浮点型，但是int('3.23e+07') 将抛出 ValueError\n",
    "# -    “str”，表示其他所有值\n",
    "# \n",
    "# The audit_file function should return a dictionary containing fieldnames and a \n",
    "# SET of the types that can be found in the field. e.g.\n",
    "# {\"field1\": set([type(float()), type(int()), type(str())]),\n",
    "#  \"field2\": set([type(str())]),\n",
    "#   ....\n",
    "# }\n",
    "# The type() function returns a type object describing the argument given to the \n",
    "# function. You can also use examples of objects to create type objects, e.g.\n",
    "# type(1.1) for a float: see the test function below for examples.\n",
    "# audit_file 函数应该返回一个字典，其中包含字段名称和可以在该字段中找到的类型集。例如\n",
    "# {\"field1\": set([type(float()), type(int()), type(str())]),\n",
    "#  \"field2\": set([type(str())]),\n",
    "#   ....\n",
    "# }\n",
    "# type() 函数返回的是类型对象，描述了提供给该函数的参数。你还可以使用对象示例创建类型对象，例如 type(1.1) \n",
    "# 表示浮点型：具体示例请参阅下面的测试函数。\n",
    "# \n",
    "# Note that the first three rows (after the header row) in the cities.csv file\n",
    "# are not actual data points. The contents of these rows should note be included\n",
    "# when processing data types. Be sure to include functionality in your code to\n",
    "# skip over or detect these rows.\n",
    "# 注意，cities.csv 文件的前三行（标题行之后）不是实际的数据点。在处理数据类型时，不应该包含这些行的内容。\n",
    "# 确保在代码中包含相关功能，以便跳过或检测出这些行。\n",
    "\n",
    "# <type 'float'>\n",
    "# <type 'str'>\n",
    "# <type 'int'>\n",
    "# <type 'str'>\n",
    "# <type 'NoneType'>\n",
    "\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities.csv'\n",
    "\n",
    "# FIELDS = [\"areaLand\", \"areaMetro\"]\n",
    "FIELDS = [\"name\", \"timeZone_label\", \"utcOffset\", \"homepage\", \"governmentType_label\",\n",
    "          \"isPartOf_label\", \"areaCode\", \"populationTotal\", \"elevation\",\n",
    "          \"maximumElevation\", \"minimumElevation\", \"populationDensity\",\n",
    "          \"wgs84_pos#lat\", \"wgs84_pos#long\", \"areaLand\", \"areaMetro\", \"areaUrban\"]\n",
    "\n",
    "def skip_lines(input_file, skip):\n",
    "    for i in range(0,skip):\n",
    "        next(input_file)\n",
    "\n",
    "def is_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def is_int(s):\n",
    "    try:\n",
    "        int(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def is_null(s):\n",
    "    if s == 'NULL' or s == '':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        # s is None or s == ''\n",
    "       \n",
    "\n",
    "def is_list(s):\n",
    "    if s[0] == '{':\n",
    "        # s.startwith('{')\n",
    "       \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "    \n",
    "def audit_file(filename, fields):\n",
    "    \n",
    "    fieldtypes = {}\n",
    "    for field in fields:\n",
    "        fieldtypes[field] = set()\n",
    "        \n",
    "    \n",
    "    with open(filename,'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        header = reader.fieldnames\n",
    "        print header\n",
    "        skip_lines(reader,3)\n",
    "    \n",
    "    # for field in fields:\n",
    "    #     fieldtypes[field] = set()\n",
    "        for row in reader:\n",
    "            for field in fields:\n",
    "                # if is_null(row[field]):\n",
    "                #     print 'Y'\n",
    "                \n",
    "                if is_null(row[field]):\n",
    "                    fieldtypes[field].add(type(None))\n",
    "                elif is_float(row[field]):\n",
    "                    fieldtypes[field].add(type(float()))\n",
    "                elif is_int(row[field]):\n",
    "                    fieldtypes[field].add(type(int()))\n",
    "                elif is_list(row[field]):\n",
    "                    fieldtypes[field].add(type(list()))\n",
    "                # elif is_null(row[field]):\n",
    "                #     print 'Y'\n",
    "                #     fieldtypes[field].add(type(None))\n",
    "                else:\n",
    "                    fieldtypes[field].add(type(str()))\n",
    "         \n",
    "            \n",
    "    # print header\n",
    "        \n",
    "            \n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    \n",
    "    return fieldtypes\n",
    "\n",
    "\n",
    "    \n",
    "# def test():\n",
    "#     fieldtypes = audit_file(CITIES, FIELDS)\n",
    "# \n",
    "#     pprint.pprint(fieldtypes)\n",
    "# \n",
    "#     assert fieldtypes[\"areaLand\"] == set([type(1.1), type([]), type(None)])\n",
    "#     assert fieldtypes['areaMetro'] == set([type(1.1), type(None)])\n",
    "#     \n",
    "# if __name__ == \"__main__\":\n",
    "#     test()\n",
    "\n",
    "audit_file(CITIES,FIELDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print is_list('9')\n",
    "def is_list(s):\n",
    "    if s[0] == '{':\n",
    "        # s.startwith('{')\n",
    "       \n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习: 修复区域\n",
    "# In this problem set you work with cities infobox data, audit it, come up with a\n",
    "# cleaning idea and then clean it up.\n",
    "# 在此习题集中，你将处理城市 infobox 数据，对数据进行审核，然后想出清理方法并清理数据。\n",
    "# \n",
    "# Since in the previous quiz you made a decision on which value to keep for the\n",
    "# \"areaLand\" field, you now know what has to be done.\n",
    "# 因为在上一道测验中，你已经决定针对“areaLand”字段保留哪个值，你现在知道该如何操作了。\n",
    "# \n",
    "# Finish the function fix_area(). It will receive a string as an input, and it\n",
    "# has to return a float representing the value of the area or None.\n",
    "# You have to change the function fix_area. You can use extra functions if you\n",
    "# like, but changes to process_file will not be taken into account.\n",
    "# The rest of the code is just an example on how this function can be used.\n",
    "# 完成函数 fix_area()。它将获得字符串输入，并需要返回表示面积值的浮点值或 None。你需要更改fix_area 函数。\n",
    "# 你可以使用其他函数，但是对 process_file 的更改不会计入评估范围。\n",
    "# 代码的其余部分只是用来展示可以如何使用该函数的示例。\n",
    "\n",
    "import codecs\n",
    "import csv\n",
    "import json\n",
    "import pprint\n",
    "import decimal\n",
    "\n",
    "# CITIES = 'cities.csv'\n",
    "CITIES = 'cities_test.csv'\n",
    "\n",
    "\n",
    "def fix_area(area):\n",
    "    \n",
    "    if is_list(area):\n",
    "        area = area.strip('{').strip('}')\n",
    "        area_list = area.split('|')\n",
    "        s1 = area_list[0]\n",
    "        s2 = area_list[1]\n",
    "        if area.find('e') == -1:\n",
    "           s1 = '%1e' % Decimal(s1)\n",
    "           s2 = '%1e' % Decimal(s2)\n",
    "        \n",
    "        if s1.find('e') > s2.find('e'):\n",
    "            return float(area_list[0])\n",
    "        else:\n",
    "            return float(area_list[1])\n",
    "    elif is_null(area):\n",
    "        return None\n",
    "    else:\n",
    "        return float(area)\n",
    "    \n",
    "        \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # return area\n",
    "\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    # CHANGES TO THIS FUNCTION WILL BE IGNORED WHEN YOU SUBMIT THE EXERCISE\n",
    "    data = []\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "\n",
    "        #skipping the extra metadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # calling your function to fix the area value\n",
    "            \n",
    "            if \"areaLand\" in line:\n",
    "                line[\"areaLand\"] = fix_area(line[\"areaLand\"])\n",
    "            data.append(line)\n",
    "           \n",
    " \n",
    "            \n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = process_file(CITIES)\n",
    "\n",
    "    print \"Printing three example results:\"\n",
    "    for n in range(5,8):\n",
    "        pprint.pprint(data[n][\"areaLand\"])\n",
    "  \n",
    "    assert data[3][\"areaLand\"] == None        \n",
    "    assert data[8][\"areaLand\"] == 55166700.0\n",
    "    assert data[20][\"areaLand\"] == 14581600.0\n",
    "    assert data[33][\"areaLand\"] == 20564500.0    \n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing 20 results:\n['Kud']\n['Kuju']\n['Kumbhraj']\n['Kumhari']\n['Kunigal']\n['Kurgunta']\n['Athens']\n['Demopolis']\n['Chelsea Alabama']\n['Pell City Alabama']\n['City of Northport']\n['Sand Point']\n['Unalaska Alaska']\n['City of Menlo Park']\n['Negtemiut', 'Nightmute']\n['Fairbanks Alaska']\n['Homer']\n['Ketchikan Alaska']\n['Nuniaq', 'Old Harbor']\n['Rainier Washington']\n"
     ]
    }
   ],
   "source": [
    "# 练习: 修复姓名\n",
    "# \n",
    "# In this problem set you work with cities infobox data, audit it, come up with a\n",
    "# cleaning idea and then clean it up.\n",
    "# 在此习题集中，你将处理城市 infobox 数据，对数据进行审核，然后想出清理方法并清理数据。\n",
    "# \n",
    "# In the previous quiz you recognized that the \"name\" value can be an array (or\n",
    "# list in Python terms). It would make it easier to process and query the data\n",
    "# later if all values for the name are in a Python list, instead of being\n",
    "# just a string separated with special characters, like now.\n",
    "# 在上一道测验中，你意识到“name”值可以是数组（或用 Python 术语来说的话，是列表）。\n",
    "# 如果名称的所有值是 Python 列表（而不是用特殊字符分隔的字符串，例如现在的状况），则稍后更容易处理和查询数据。\n",
    "# \n",
    "# Finish the function fix_name(). It will recieve a string as an input, and it\n",
    "# will return a list of all the names. If there is only one name, the list will\n",
    "# have only one item in it; if the name is \"NULL\", the list should be empty.\n",
    "# The rest of the code is just an example on how this function can be used.\n",
    "# 请完成函数fix_name()。它将获得字符串输入，并返回所有名称列表。\n",
    "# 如果只有一个名称，列表将只有一项。如果名称是“NULL”，该列表应该为空。\n",
    "# 代码的其余部分只是可以用来展示如何使用该函数的示例。\n",
    "\n",
    "import codecs\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "CITIES = 'cities_test.csv'\n",
    "\n",
    "\n",
    "def fix_name(name):\n",
    "    if is_list(name):\n",
    "        name = name.strip('{').strip('}')\n",
    "        name = name.split('|')\n",
    "    elif is_null(name):\n",
    "        name = []\n",
    "    else:\n",
    "        name = [name]\n",
    "   \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        #skipping the extra metadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            \n",
    "            \n",
    "            if \"name\" in line:\n",
    "                line[\"name\"] = fix_name(line[\"name\"])\n",
    "            data.append(line)\n",
    "            # print line[\"name\"] \n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = process_file(CITIES)\n",
    "\n",
    "    print \"Printing 20 results:\"\n",
    "    for n in range(20):\n",
    "        pprint.pprint(data[n][\"name\"])\n",
    "\n",
    "    assert data[14][\"name\"] == ['Negtemiut', 'Nightmute']\n",
    "    assert data[9][\"name\"] == ['Pell City Alabama']\n",
    "    assert data[3][\"name\"] == ['Kumhari']\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()\n",
    "\n",
    "# process_file(CITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Athens: 34.789722222222224 -86.96944444444445 != 34.7897 -86.9694\nDemopolis: 32.50944444444445 -87.83722222222222 != 32.5094 -87.8372\nChelsea Alabama: 33.329166666666666 -86.65083333333334 != 33.3292 -86.6508\nPell City Alabama: 33.57083333333333 -86.27388888888889 != 33.5708 -86.2739\nCity of Northport: 33.25388888888889 -87.59222222222222 != 33.2539 -87.5922\nSand Point: 55.336666666666666 -160.49333333333334 != 55.3367 -160.493\nUnalaska Alaska: 53.888888888888886 -166.52722222222224 != 53.8889 -166.527\nCity of Menlo Park: 37.454166666666666 -122.17861111111111 != 37.4542 -122.179\n{Negtemiut|Nightmute}: 60.49138888888889 -164.82611111111112 != 60.4914 -164.826\nFairbanks Alaska: 64.84361111111112 -147.72305555555556 != 64.8436 -147.723\nHomer: 59.643055555555556 -151.52583333333334 != 59.6431 -151.526\nKetchikan Alaska: 55.35 -131.67333333333335 != 55.35 -131.673\n{Nuniaq|Old Harbor}: 57.19722222222222 -153.30777777777777 != 57.1972 -153.308\nRainier Washington: 46.89083333333333 -122.68972222222222 != 46.8908 -122.69\nCity of Blaine: 48.988055555555555 -122.74361111111111 != 48.9881 -122.744\nFerndale Washington: 48.84888888888889 -122.59027777777777 != 48.8489 -122.59\nMabton Washington: 46.211666666666666 -119.99638888888889 != 46.2117 -119.996\nZillah Washington: 46.40361111111111 -120.26083333333334 != 46.4036 -120.261\nKenova West Virginia: 38.39972222222222 -82.57861111111112 != 38.3997 -82.5786\nFitchburg Wisconsin: 43.006388888888885 -89.43138888888889 != 43.0064 -89.4314\nStoughton Wisconsin: 42.92111111111111 -89.22444444444444 != 42.9211 -89.2244\nWatertown Wisconsin: 43.2 -88.71666666666667 != 43.2 -88.7167\nLaCrosse Wisconsin: 43.81333333333333 -91.23305555555555 != 43.8133 -91.2331\nWauwatosa Wisconsin: 43.05888888888889 -88.0261111111111 != 43.0589 -88.0261\nOsseo Wisconsin: 44.57833333333333 -91.21833333333333 != 44.5783 -91.2183\nMuskego Wisconsin: 42.90123611111111 -88.1246388888889 != 42.9012 -88.1246\nClintonville Wisconsin: 44.62416666666667 -88.75805555555556 != 44.6242 -88.7581\nHartford Wisconsin: 43.318333333333335 -88.3788888888889 != 43.3183 -88.3789\nCity of Spokane Valley Washington: 47.67333333333333 -117.23944444444444 != 47.6733 -117.239\nNULL: 45.75 126.63333333333334 != 45.75 126.633\nDortmund: 51.516666666666666 7.466666666666667 != 51.5167 7.46667\nStratford Iowa: 42.270833333333336 -93.92694444444444 != 42.2708 -93.9269\nForest City Iowa: 43.261944444444445 -93.64027777777778 != 43.2619 -93.6403\n"
     ]
    }
   ],
   "source": [
    "# 练习: 交叉字段审查\n",
    "# In this problem set you work with cities infobox data, audit it, come up with a\n",
    "# cleaning idea and then clean it up.\n",
    "# 在此习题集中，你将处理城市 infobox 数据，对数据进行审核，然后想出清理方法并清理数据。\n",
    "# \n",
    "# If you look at the full city data, you will notice that there are couple of\n",
    "# values that seem to provide the same information in different formats: \"point\"\n",
    "# seems to be the combination of \"wgs84_pos#lat\" and \"wgs84_pos#long\". However,\n",
    "# we do not know if that is the case and should check if they are equivalent.\n",
    "# 如果你查看完整的城市数据，会发现有几个值似乎提供的是同一信息，只是格式不同：\n",
    "# “point”似乎是“wgs84_pos#lat”和“wgs84_pos#long”的结合体。但是，我们不知道是否是这种情况，\n",
    "# # 你应该检查它们是否相等。\n",
    "# \n",
    "# Finish the function check_loc(). It will recieve 3 strings: first, the combined\n",
    "# value of \"point\" followed by the separate \"wgs84_pos#\" values. You have to\n",
    "# extract the lat and long values from the \"point\" argument and compare them to\n",
    "# the \"wgs84_pos# values, returning True or False.\n",
    "# 完成函数check_loc()。它应该获得 3 个字符串：首先是“point”的值后面跟上单独的“wgs84_pos#”值。\n",
    "# # 你应该从“point”参数中提取lat和长值，并将它们与“wgs84_pos#”值对比，返回 True 或 False。\n",
    "# \n",
    "# Note that you do not have to fix the values, only determine if they are\n",
    "# consistent. To fix them in this case you would need more information. Feel free\n",
    "# to discuss possible strategies for fixing this on the discussion forum.\n",
    "# 注意，你不需要修正这些值，只需判断它们是否保持一致。要修正这些值，你需要更多信息。\n",
    "# 欢迎在论坛上讨论如何修正这些值。\n",
    "# \n",
    "# The rest of the code is just an example on how this function can be used.\n",
    "# Changes to \"process_file\" function will not be taken into account for grading.\n",
    "# 代码的其余部分只是可以用来展示如何使用该函数的示例。我们在打分时，不会考虑对“process_file”函数做出的更改。\n",
    "\n",
    "import csv\n",
    "import pprint\n",
    "\n",
    "# CITIES = 'cities.csv'\n",
    "CITIES = 'cities_test.csv'\n",
    "\n",
    "\n",
    "def check_loc(point, lat, longi):\n",
    "    # YOUR CODE HERE\n",
    "    point = point.split()\n",
    "    if point[0] == lat and point[1] == longi:\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "def process_file(filename):\n",
    "    data = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        #skipping the extra matadata\n",
    "        for i in range(3):\n",
    "            l = reader.next()\n",
    "        # processing file\n",
    "        for line in reader:\n",
    "            # print line[\"point\"].split(),\": {\",line[\"wgs84_pos#lat\"],\": \",line[\"wgs84_pos#long\"],\" }\"\n",
    "            # calling your function to check the location\n",
    "            result = check_loc(line[\"point\"], line[\"wgs84_pos#lat\"], line[\"wgs84_pos#long\"])\n",
    "            if not result:\n",
    "                print \"{}: {} != {} {}\".format(line[\"name\"], line[\"point\"], line[\"wgs84_pos#lat\"], \n",
    "                                               line[\"wgs84_pos#long\"])\n",
    "            data.append(line)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    assert check_loc(\"33.08 75.28\", \"33.08\", \"75.28\") == True\n",
    "    assert check_loc(\"44.57833333333333 -91.21833333333333\", \"44.5783\", \"-91.2183\") == False\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test()\n",
    "\n",
    "process_file(CITIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
