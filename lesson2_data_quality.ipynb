{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#XML\n",
    "#!/usr/bin/env python\n",
    "# Your task here is to extract data from xml on authors of an article\n",
    "# and add it to a list, one item for an author.\n",
    "# See the provided data structure for the expected format.\n",
    "# The tags for first name, surname and email should map directly\n",
    "# to the dictionary keys\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "article_file = \"exampleResearchArticle.xml\"\n",
    "\n",
    "\n",
    "def get_root(fname):\n",
    "    tree = ET.parse(fname)\n",
    "    return tree.getroot()\n",
    "\n",
    "\n",
    "def get_authors(root):\n",
    "    authors = []\n",
    "    for author in root.findall('./fm/bibl/aug/au'):\n",
    "        #answer:\n",
    "        # for i in insr:\n",
    "        #     data[\"insr\"].append(i.attrib[\"iid\"])\n",
    "        insr_group = []\n",
    "        for insr in author.findall('insr'):\n",
    "            insr_group.append(insr.get('iid'))\n",
    "        data = {\n",
    "                \"fnm\": author.find('fnm').text,\n",
    "                \"snm\": author.find('snm').text,\n",
    "                \"email\": author.find('email').text,\n",
    "                \"insr\":insr_group\n",
    "        }\n",
    "        \n",
    "            \n",
    "\n",
    "        # YOUR CODE HERE\n",
    "\n",
    "        authors.append(data)\n",
    "\n",
    "    return authors\n",
    "\n",
    "\n",
    "def test():\n",
    "    solution = [{'fnm': 'Omer', 'snm': 'Mei-Dan', 'email': 'omer@extremegate.com'}, {'fnm': 'Mike', 'snm': 'Carmont', 'email': 'mcarmont@hotmail.com'}, {'fnm': 'Lior', 'snm': 'Laver', 'email': 'laver17@gmail.com'}, {'fnm': 'Meir', 'snm': 'Nyska', 'email': 'nyska@internet-zahav.net'}, {'fnm': 'Hagay', 'snm': 'Kammar', 'email': 'kammarh@gmail.com'}, {'fnm': 'Gideon', 'snm': 'Mann', 'email': 'gideon.mann.md@gmail.com'}, {'fnm': 'Barnaby', 'snm': 'Clarck', 'email': 'barns.nz@gmail.com'}, {'fnm': 'Eugene', 'snm': 'Kots', 'email': 'eukots@gmail.com'}]\n",
    "    \n",
    "    root = get_root(article_file)\n",
    "    data = get_authors(root)\n",
    "\n",
    "    assert data[0] == solution[0]\n",
    "    assert data[1][\"fnm\"] == solution[1][\"fnm\"]\n",
    "\n",
    "\n",
    "# test()\n",
    "# get_authors(get_root(article_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE BeautifulSoup\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Please note that the function 'make_request' is provided for your reference only.\n",
    "# You will not be able to to actually use it from within the Udacity web UI.\n",
    "# Your task is to process the HTML using BeautifulSoup, extract the hidden\n",
    "# form field values for \"__EVENTVALIDATION\" and \"__VIEWSTATE\" and set the appropriate\n",
    "# values in the data dictionary.\n",
    "# All your changes should be in the 'extract_data' function\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "\n",
    "html_page = \"page_source.html\"\n",
    "\n",
    "\n",
    "def extract_data(page):\n",
    "    data = {\"eventvalidation\": \"\",\n",
    "            \"viewstate\": \"\"}\n",
    "    with open(page, \"r\") as html:\n",
    "        # do something here to find the necessary values\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        data[\"eventvalidation\"]  = soup.find(id=\"__EVENTVALIDATION\")['value']\n",
    "        data[\"viewstate\"] = soup.find(id=\"__VIEWSTATE\")['value']\n",
    "        pass\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def make_request(data):\n",
    "    eventvalidation = data[\"eventvalidation\"]\n",
    "    viewstate = data[\"viewstate\"]\n",
    "    print 'befor request!!!!!'\n",
    "    r = requests.post(\"http://www.transtats.bts.gov/Data_Elements.aspx?Data=2\",\n",
    "                    data={'AirportList': \"BOS\",\n",
    "                          'CarrierList': \"VX\",\n",
    "                          'Submit': 'Submit',\n",
    "                          \"__EVENTTARGET\": \"\",\n",
    "                          \"__EVENTARGUMENT\": \"\",\n",
    "                          \"__EVENTVALIDATION\": eventvalidation,\n",
    "                          \"__VIEWSTATE\": viewstate\n",
    "                    })\n",
    "    print 'request Done!'\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = extract_data(html_page)\n",
    "    assert data[\"eventvalidation\"] != \"\"\n",
    "    assert data[\"eventvalidation\"].startswith(\"/wEWjAkCoIj1ng0\")\n",
    "    assert data[\"viewstate\"].startswith(\"/wEPDwUKLTI\")\n",
    "\n",
    "    \n",
    "# test()\n",
    "make_request(extract_data(html_page))\n",
    "\n",
    "print make_request(extract_data(html_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beautifulSoup练习\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "html_page = \"page_source.html\"\n",
    "\n",
    "\n",
    "def extract_carriers(page):\n",
    "    data = []\n",
    "\n",
    "    with open(page, \"r\") as html:\n",
    "        # do something here to find the necessary values\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        for option_value in  soup.find(id=\"CarrierList\").find_all('option'):\n",
    "            if option_value['value'].find('All') == -1:\n",
    "                data.append(option_value['value']) \n",
    "\n",
    "    return data\n",
    "\n",
    "def extract_airports(page):\n",
    "    data = []\n",
    "    with open(page, \"r\") as html:\n",
    "        # do something here to find the necessary values\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "        for option_value in  soup.find(id=\"AirportList\").find_all('option'):\n",
    "            if option_value['value'].find('All') == -1:\n",
    "                data.append(option_value['value']) \n",
    "        \n",
    "\n",
    "    return data\n",
    "\n",
    "def make_request(data):\n",
    "    eventvalidation = data[\"eventvalidation\"]\n",
    "    viewstate = data[\"viewstate\"]\n",
    "    airport = data[\"airport\"]\n",
    "    carrier = data[\"carrier\"]\n",
    "    print 'Before'\n",
    "    r = s.post(\"https://www.transtats.bts.gov/Data_Elements.aspx?Data=2\",\n",
    "               data = ((\"__EVENTTARGET\", \"\"),\n",
    "                       (\"__EVENTARGUMENT\", \"\"),\n",
    "                       (\"__VIEWSTATE\", viewstate),\n",
    "                       (\"__VIEWSTATEGENERATOR\",viewstategenerator),\n",
    "                       (\"__EVENTVALIDATION\", eventvalidation),\n",
    "                       (\"CarrierList\", carrier),\n",
    "                       (\"AirportList\", airport),\n",
    "                       (\"Submit\", \"Submit\")))\n",
    "\n",
    "    return r.text\n",
    "\n",
    "\n",
    "def test():\n",
    "    data = extract_carriers(html_page)\n",
    "    assert len(data) == 16\n",
    "    assert \"FL\" in data\n",
    "    assert \"NK\" in date\n",
    "# if __name__ == \"__main__\":\n",
    "#     test()\n",
    "    \n",
    "print extract_carriers(html_page)\n",
    "print extract_airports(html_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#假设你将上两个练习中的代码与关于如何构建请求的课程中代码相结合，并将所有数据下载到了本地。\n",
    "#文件位于目录“data”下，按照航空公司和机场命名：\"{}-{}.html\".format(carrier, airport)，例如“FL-ATL.html”。\n",
    "#包含航班信息的表格具有一个表格类“dataTDRight”。你的任务是使用“process_file()”从该表格中提取航班数据，\n",
    "#并作为字典列表，每个字典包含文件中的相关信息和表格行。以下是你应该返回的数据结构示例：\n",
    "#Note - year, month, and the flight data should be integers.\n",
    "#You should skip the rows that contain the TOTAL data for a year.\n",
    "#注意：年月和航班数据应该是整型。你应该跳过包含一年 TOTAL 数据的行。\n",
    "#你可以使用几个辅助函数来处理数据文件。为了方便打分，请勿更改这些辅助函数。你只需更改“process_file()”函数。\n",
    "#上述标签中的“data/FL-ATL.html”文件只是完整数据的一部分，涵盖的是截止 2003 年的数据。\n",
    "#test() 代码将使用完整的表格，但是给定文件应该提供一个你将获得的数据示例。\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "\n",
    "datadir = \"data\"\n",
    "\n",
    "\n",
    "def open_zip(datadir):\n",
    "    with ZipFile('{0}.zip'.format(datadir), 'r') as myzip:\n",
    "        myzip.extractall()\n",
    "\n",
    "\n",
    "def process_all(datadir):\n",
    "    files = os.listdir(datadir)\n",
    "    return files\n",
    "\n",
    "\n",
    "def process_file(f):\n",
    "    \"\"\"\n",
    "    This function extracts data from the file given as the function argument in\n",
    "    a list of dictionaries. This is example of the data structure you should\n",
    "    return:\n",
    "\n",
    "    data = [{\"courier\": \"FL\",\n",
    "             \"airport\": \"ATL\",\n",
    "             \"year\": 2012,\n",
    "             \"month\": 12,\n",
    "             \"flights\": {\"domestic\": 100,\n",
    "                         \"international\": 100}\n",
    "            },\n",
    "            {\"courier\": \"...\"}\n",
    "    ]\n",
    "\n",
    "\n",
    "    Note - year, month, and the flight data should be integers.\n",
    "    You should skip the rows that contain the TOTAL data for a year.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    info = {}\n",
    "    info[\"courier\"], info[\"airport\"] = f[:6].split(\"-\")\n",
    "    # Note: create a new dictionary for each entry in the output data list.\n",
    "    # If you use the info dictionary defined here each element in the list \n",
    "    # will be a reference to the same info dictionary.\n",
    "    with open(\"{}/{}\".format(datadir, f), \"r\") as html:\n",
    "        print 'start'\n",
    "\n",
    "        \n",
    "        soup = BeautifulSoup(html,\"lxml\")\n",
    "        trs = soup.find_all(\"tr\", { \"class\" : \"dataTDRight\" })\n",
    "        entry = {}\n",
    "        entry[\"courier\"], info[\"airport\"] = f[:6].split(\"-\")\n",
    "        \n",
    "        # print  trs[0].find_all('td')[0].text\n",
    "        for tr in trs:\n",
    "            if tr.find_all('td')[1].text != 'TOTAL' :\n",
    "             year = tr.find_all('td')[0].text\n",
    "             month = tr.find_all('td')[1].text\n",
    "             domestic = (tr.find_all('td')[2].text).replace(',','')\n",
    "                \n",
    "                \n",
    "                \n",
    "             international = (tr.find_all('td')[3].text).replace(',','')\n",
    "                # print domestic\n",
    "                # print international\n",
    "             entry['year'] = int(year)\n",
    "             entry['month'] = int(month)\n",
    "             entry['flights'] = {'domestic':int(domestic),\n",
    "                                   'international':int(international)}\n",
    "                \n",
    "             data.append(entry) \n",
    "            \n",
    "            \n",
    "            \n",
    "                \n",
    "            # else:\n",
    "            #     info['year'] = tr.find_all('td')[0].text\n",
    "            #     info['month'] = tr.find_all('td')[1].text\n",
    "            #     info_in['domestic'] = tr.find_all('td')[2].text\n",
    "            #     print info_in['domestic']\n",
    "            #     info_in['international'] = tr.find_all('td')[3].text\n",
    "            #     info['flights'] = info_in\n",
    "               \n",
    "         \n",
    "           \n",
    "            # if tr.find_all('td')[1].text == 'TOTAL':  \n",
    "            #     print tr.find_all('td')[0].text\n",
    "            #     print tr.find_all('td')[2].text\n",
    "            #     print tr.find_all('td')[3].text\n",
    "            #     print tr.find_all('td')[4].text\n",
    "            # else:\n",
    "            #     print tr.find_all('td')[0].text\n",
    "            #     print tr.find_all('td')[1].text\n",
    "            #     print tr.find_all('td')[2].text\n",
    "            #     print tr.find_all('td')[3].text\n",
    "               \n",
    "            # \n",
    "       \n",
    "       \n",
    "        \n",
    "    print 'end'\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def test():\n",
    "    print \"Running a simple test...\"\n",
    "    open_zip(datadir)\n",
    "    files = process_all(datadir)\n",
    "    data = []\n",
    "    # Test will loop over three data files.\n",
    "    for f in files:\n",
    "        data += process_file(f)\n",
    "        \n",
    "    assert len(data) == 399  # Total number of rows\n",
    "    for entry in data[:3]:\n",
    "        assert type(entry[\"year\"]) == int\n",
    "        assert type(entry[\"month\"]) == int\n",
    "        assert type(entry[\"flights\"][\"domestic\"]) == int\n",
    "        assert len(entry[\"airport\"]) == 3\n",
    "        assert len(entry[\"courier\"]) == 2\n",
    "    assert data[0][\"courier\"] == 'FL'\n",
    "    assert data[0][\"month\"] == 10\n",
    "    assert data[-1][\"airport\"] == \"ATL\"\n",
    "    assert data[-1][\"flights\"] == {'international': 108289, 'domestic': 701425}\n",
    "    \n",
    "    print \"... success!\"\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     test()\n",
    "\n",
    "process_file('FL-ATL.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "PATENTS = 'patent.data'\n",
    "\n",
    "def get_root(fname):\n",
    "\n",
    "    tree = ET.parse(fname)\n",
    "    return tree.getroot()\n",
    "\n",
    "\n",
    "# get_root(PATENTS)\n",
    "\n",
    "# 解答\n",
    "\n",
    "# 很棒的尝试！问题出在：\n",
    "# 不应该在遍历输入文件的每一行时，\n",
    "# 就把输出文件名全部循环切换一遍哦。\n",
    "# \n",
    "# 讲一下我自己的思路，供你参考：\n",
    "# \n",
    "# 必需步骤：\n",
    "# \n",
    "# 无论如何是需要打开并遍历 输入文件 的，这个逃不掉。\n",
    "# 输出文件 是个变量。肯定需要循环下列切换操作：\n",
    "# a. 打开输出文件\n",
    "# b. 关闭输出文件\n",
    "# c. 输出文件名加 1\n",
    "# 难点在于 a, b, c 如何分组，以及何时进行切换操作。\n",
    "# \n",
    "# 何时切换很容易解决，必须是 遇到 '<?xml' 时 进行。\n",
    "# 但直接硬来会出现问题。\n",
    "# \n",
    "# 初次（不正确的）尝试：\n",
    "# \n",
    "# a. 打开\n",
    "# b. 关闭\n",
    "# c. +1\n",
    "# \n",
    "# a. 打开\n",
    "# b. 关闭\n",
    "# c. +1\n",
    "# \n",
    "# a. 打开\n",
    "# b. 关闭\n",
    "# c. +1\n",
    "# \n",
    "# ……\n",
    "# 每次遇到 '<?xml' 时这样分组切换的话，\n",
    "# 虽然文件名有 +1，但打开后却直接关掉了，\n",
    "# 导致 并没有机会使用输出文件 :joy:。\n",
    "# \n",
    "# 那么如何解决呢？\n",
    "# \n",
    "# 只要保持有输出文件处于打开状态就好了。\n",
    "# 我们可以首先 单独打开一次输出文件，\n",
    "# 然后每次遇到 '<?xml' 时，切换步骤变成 “关闭 、+1、再打开”：\n",
    "# （总体顺序没有变，但是分组变化了）\n",
    "# \n",
    "# a. 首次打开（循环之外单独进行）\n",
    "# \n",
    "# b. 关闭\n",
    "# c. +1\n",
    "# a. 打开\n",
    "# \n",
    "# b. 关闭\n",
    "# c. +1\n",
    "# a. 打开\n",
    "# \n",
    "# b. 关闭\n",
    "# c. +1\n",
    "# a. 打开\n",
    "\n",
    "# def split_file(filename):\n",
    "#     with open(filename) as infile:\n",
    "#         n = -1 # 由于第一次遇到 '<?xml' 时会关闭文件，导致跳空一次\n",
    "#                # 所以临时从 -1 开始，保证能从 0 正式开始\n",
    "#         outfile = open('{}-{}'.format(filename, n), 'w') # 单独打开\n",
    "# \n",
    "#         for line in infile:\n",
    "#             if line.startswith('<?xml'):\n",
    "#                 # 每次切换步骤：关闭、+1、再打开\n",
    "#                 outfile.close() \n",
    "#                 n += 1       \n",
    "#                 outfile = open('{}-{}'.format(filename, n),'w')\n",
    "# \n",
    "#             outfile.write(line)\n",
    "#             \n",
    "#         outfile.close() # 记得用完关闭\n",
    "\n",
    "\n",
    "def split_file(filename):\n",
    "    \"\"\"\n",
    "    Split the input file into separate files, each containing a single patent.\n",
    "    As a hint - each patent declaration starts with the same line that was\n",
    "    causing the error found in the previous exercises.\n",
    "    \n",
    "    The new files should be saved with filename in the following format:\n",
    "    \"{}-{}\".format(filename, n) where n is a counter, starting from 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    line_num = 0\n",
    "  \n",
    "    line_start = 0\n",
    "    \n",
    "    n = 0\n",
    "    \n",
    "   \n",
    "    for line in lines[1:]:\n",
    "        # print lines.index(line)\n",
    "        line_num = line_num + 1\n",
    "        if line.find('xml version=\"1.0\"') != -1 or line_num == (len(lines) - 1):\n",
    "            print line_num\n",
    "            \n",
    "            with open(\"{}-{}\".format(PATENTS, n),'w') as f:\n",
    "                \n",
    "               for line in  lines[line_start:line_num]:\n",
    "                    f.write(line)\n",
    "               n = n + 1\n",
    "               line_start = line_num\n",
    " \n",
    "   \n",
    "    pass\n",
    "   \n",
    "   \n",
    "\n",
    "def test():\n",
    "    split_file(PATENTS)\n",
    "    for n in range(4):\n",
    "        try:\n",
    "            fname = \"{}-{}\".format(PATENTS, n)\n",
    "            f = open(fname, \"r\")\n",
    "            if not f.readline().startswith(\"<?xml\"):\n",
    "                print \"You have not split the file {} in the correct boundary!\".format(fname)\n",
    "            f.close()\n",
    "        except:\n",
    "            print \"Could not find file {}. Check if the filename is correct!\".format(fname)\n",
    "\n",
    "\n",
    "# test()\n",
    "\n",
    "split_file(PATENTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
